* nodejs
** 程序运行 nodejs nodejsfile 
** 模块
*** 定义模块
    #+begin_src js
      exports.doAdd = function(x,y){
          return x+y;
      };
    #+end_src

*** 内置模块 require('fs')
*** node_modules
    nodejs 定义了一个特殊的 node_modules 目录用于存放模块。例如某个模块的绝对路径是
    /home/user/hello.js，在该模块中使用 require('foo/bar')方式加载模块时，则
    nodejs 依次尝试使用以下路径。
    #+BEGIN_SRC 
  /home/user/node_modules/foo/bar
  /home/node_modules/foo/bar
  /node_modules/foo/bar
    #+END_SRC
   
*** NODE_PATH 环境变量
   与 PATH 环境变量类似，NodeJS 允许通过 NODE_PATH 环境变量来指定额外的模块搜索路径。
   NODE_PATH 环境变量中包含一到多个目录路径，路径之间在 Linux 下使用:分隔，在
   Windows 下使用;分隔。例如定义了以下 NODE_PATH 环境变量：
   
   NODE_PATH=/home/user/lib:/home/lib
    
   当使用 require('foo/bar')的方式加载模块时，则 NodeJS 依次尝试以下路径。
  #+BEGIN_SRC 
    /home/user/lib/foo/bar
    /home/lib/foo/bar
  #+END_SRC
  
** 包（package）
   我们已经知道了 JS 模块的基本单位是单个 JS 文件，但复杂些的模块往往由多个子模块组
   成。为了便于管理和使用，我们可以把由多个子模块组成的大模块称做包，并把所有子
   模块放在同一个目录里。

   在组成一个包的所有子模块中，需要有一个入口模块，入口模块的导出对象被作为包的
   导出对象。例如有以下目录结构。
#+BEGIN_SRC 
- /home/user/lib/
    - cat/
        head.js
        body.js
        main.js
#+END_SRC

其中 cat 目录定义了一个包，其中包含了 3 个子模块。main.js 作为入口模块，其内容如下：

#+BEGIN_SRC js
var head = require('./head');
var body = require('./body');

exports.create = function (name) {
    return {
        name: name,
        head: head.create(),
        body: body.create()
    };
};
#+END_SRC
在其它模块里使用包的时候，需要加载包的入口模块。接着上例，使用
require('/home/user/lib/cat/main')能达到目的，但是入口模块名称出现在路径里看上去
不是个好主意。因此我们需要做点额外的工作，让包使用起来更像是单个模块。

index.js

当模块的文件名是 index.js，加载模块时可以使用模块所在目录的路径代替模块文件路径，
因此接着上例，以下两条语句等价。

var cat = require('/home/user/lib/cat');
var cat = require('/home/user/lib/cat/index');

这样处理后，就只需要把包目录路径传递给 require 函数，感觉上整个目录被当作单个模块
使用，更有整体感。

package.json

如果想自定义入口模块的文件名和存放位置，就需要在包目录下包含一个 package.json 文件，
并在其中指定入口模块的路径。上例中的 cat 模块可以重构如下。

- /home/user/lib/
    - cat/
        + doc/
        - lib/
            head.js
            body.js
            main.js
        + tests/
        package.json

其中 package.json 内容如下。

{
    "name": "cat",
    "main": "./lib/main.js"
}

如此一来，就同样可以使用 require('/home/user/lib/cat')的方式加载模块。NodeJS 会根
据包目录下的 package.json 找到入口模块所在位置。

*** 命令行程序
    使用 NodeJS 编写的东西，要么是一个包，要么是一个命令行程序，而前者最终也会用于开发后者。
    因此我们在部署代码时需要一些技巧，让用户觉得自己是在使用一个命令行程序。

    例如我们用 NodeJS 写了个程序，可以把命令行参数原样打印出来。该程序很简单，在主模块内实现了所有功能。并且写好后，
    我们把该程序部署在/home/user/bin/node-echo.js 这个位置。为了在任何目录下都能运行该程序，我们需要使用以下终端命令。
#+BEGIN_SRC bash
$ node /home/user/bin/node-echo.js Hello World
Hello World
#+END_SRC

这种使用方式看起来不怎么像是一个命令行程序，下边的才是我们期望的方式。
#+BEGIN_SRC shell
$ node-echo Hello World
#+END_SRC

*** Linux
在 Linux 系统下，我们可以把 JS 文件当作 shell 脚本来运行，从而达到上述目的，具体步骤如下：

**** 1. 在 shell 脚本中，可以通过#!注释来指定当前脚本使用的解析器。所以我们首先在 node-echo.js
     文件顶部增加以下一行注释，表明当前脚本使用 NodeJS 解析。

#+BEGIN_SRC 
#! /usr/bin/env node
#+END_SRC   
    
NodeJS 会忽略掉位于 JS 模块首行的#!注释，不必担心这行注释是非法语句。
   
**** 2. 然后，我们使用以下命令赋予 node-echo.js 文件执行权限。
   #+BEGIN_SRC bash
     $ chmod +x /home/user/bin/node-echo.js
   #+END_SRC
    
**** 3. 最后，我们在 PATH 环境变量中指定的某个目录下，例如在/usr/local/bin 下边创建一个软链文件，
     文件名与我们希望使用的终端命令同名，命令如下：
#+BEGIN_SRC bash
     $ sudo ln -s /home/user/bin/node-echo.js /usr/local/bin/node-echo
#+END_SRC   
    
这样处理后，我们就可以在任何目录下使用 node-echo 命令了。

*** Windows
    在 Windows 系统下的做法完全不同，我们得靠.cmd 文件来解决问题。假设 node-echo.js 存放在 C:\Users\user\bin 目录，并且该目录已经添加到 PATH 环境
    变量里了。接下来需要在该目录下新建一个名为 node-echo.cmd 的文件，文件内容如下：

    @node "C:\User\user\bin\node-echo.js" %*

这样处理后，我们就可以在任何目录下使用 node-echo 命令了。

*** 工程目录
    了解了以上知识后，现在我们可以来完整地规划一个工程目录了。以编写一个命令行程序为例，一般我们
    会同时提供命令行模式和 API 模式两种使用方式，并且我们会借助三方包来编写代码。除了代码外，一个
    完整的程序也应该有自己的文档和测试用例。因此，一个标准的工程目录都看起来像下边这样。
#+BEGIN_SRC 
- /home/user/workspace/node-echo/   # 工程目录
    - bin/                          # 存放命令行相关代码
        node-echo
    + doc/                          # 存放文档
    - lib/                          # 存放 API 相关代码
        echo.js
    - node_modules/                 # 存放三方包
        + argv/
    + tests/                        # 存放测试用例
    package.json                    # 元数据文件
    README.md                       # 说明文件
#+END_SRC

其中部分文件内容如下：
#+BEGIN_SRC js
/* bin/node-echo */
var argv = require('argv'),
    echo = require('../lib/echo');
console.log(echo(argv.join(' ')));

/* lib/echo.js */
module.exports = function (message) {
    return message;
};

/* package.json */
{
    "name": "node-echo",
    "main": "./lib/echo.js"
}

#+END_SRC
以上例子中分类存放了不同类型的文件，并通过 node_moudles 目录直接使用三方包名加载模块。此外，定义了 package.json 之后，node-echo 目录也可
被当作一个包来使用。

NPM

NPM 是随同 NodeJS 一起安装的包管理工具，能解决 NodeJS 代码部署上的很多问题，常见的使用场景有以下几种：

  * 允许用户从 NPM 服务器下载别人编写的三方包到本地使用。
   
  * 允许用户从 NPM 服务器下载并安装别人编写的命令行程序到本地使用。
   
  * 允许用户将自己编写的包或命令行程序上传到 NPM 服务器供别人使用。
   
可以看到，NPM 建立了一个 NodeJS 生态圈，NodeJS 开发者和用户可以在里边互通有无。以下分别介绍这三种场景下怎样使用 NPM。

下载三方包

需要使用三方包时，首先得知道有哪些包可用。虽然 npmjs.org 提供了个搜索框可以根据包名来搜索，但如果连想使用的三方包的名字都不确定的话，
就请百度一下吧。知道了包名后，比如上边例子中的 argv，就可以在工程目录下打开终端，使用以下命令来下载三方包。

$ npm install argv
...
argv@0.0.2 node_modules\argv

下载好之后，argv 包就放在了工程目录下的 node_modules 目录中，因此在代码中只需要通过 require('argv')的方式就好，无需指定三方包路径。

以上命令默认下载最新版三方包，如果想要下载指定版本的话，可以在包名后边加上@<version>，例如通过以下命令可下载 0.0.1 版的 argv。

$ npm install argv@0.0.1
...
argv@0.0.1 node_modules\argv

如果使用到的三方包比较多，在终端下一个包一条命令地安装未免太人肉了。因此 NPM 对 package.json 的字段做了扩展，允许在其中申明三方包依赖。
因此，上边例子中的 package.json 可以改写如下：

{
    "name": "node-echo",
    "main": "./lib/echo.js",
    "dependencies": {
        "argv": "0.0.2"
    }
}

这样处理后，在工程目录下就可以使用 npm install 命令批量安装三方包了。更重要的是，当以后 node-echo 也上传到了 NPM 服务器，别人下载这个包时
，NPM 会根据包中申明的三方包依赖自动下载进一步依赖的三方包。例如，使用 npm install node-echo 命令时，NPM 会自动创建以下目录结构。

- project/
    - node_modules/
        - node-echo/
            - node_modules/
                + argv/
            ...
    ...

如此一来，用户只需关心自己直接使用的三方包，不需要自己去解决所有包的依赖关系。

安装命令行程序

从 NPM 服务上下载安装一个命令行程序的方法与三方包类似。例如上例中的 node-echo 提供了命令行使用方式，只要 node-echo 自己配置好了相关的
package.json 字段，对于用户而言，只需要使用以下命令安装程序。

$ npm install node-echo -g

参数中的-g 表示全局安装，因此 node-echo 会默认安装到以下位置，并且 NPM 会自动创建好 Linux 系统下需要的软链文件或 Windows 系统下需要的.cmd 文件
。

- /usr/local/               # Linux 系统下
    - lib/node_modules/
        + node-echo/
        ...
    - bin/
        node-echo
        ...
    ...

- %APPDATA%\npm\            # Windows 系统下
    - node_modules\
        + node-echo\
        ...
    node-echo.cmd
    ...

发布代码

第一次使用 NPM 发布代码前需要注册一个账号。终端下运行 npm adduser，之后按照提示做即可。账号搞定后，接着我们需要编辑 package.json 文件，加
入 NPM 必需的字段。接着上边 node-echo 的例子，package.json 里必要的字段如下。

{
    "name": "node-echo",           # 包名，在 NPM 服务器上须要保持唯一
    "version": "1.0.0",            # 当前版本号
    "dependencies": {              # 三方包依赖，需要指定包名和版本号
        "argv": "0.0.2"
      },
    "main": "./lib/echo.js",       # 入口模块位置
    "bin" : {
        "node-echo": "./bin/node-echo"      # 命令行程序名和主模块位置
    }
}

之后，我们就可以在 package.json 所在目录下运行 npm publish 发布代码了。

版本号

使用 NPM 下载和发布代码时都会接触到版本号。NPM 使用语义版本号来管理代码，这里简单介绍一下。

语义版本号分为 X.Y.Z 三位，分别代表主版本号、次版本号和补丁版本号。当代码变更时，版本号按以下原则更新。

+ 如果只是修复 bug，需要更新 Z 位。

+ 如果是新增了功能，但是向下兼容，需要更新 Y 位。

+ 如果有大变动，向下不兼容，需要更新 X 位。

版本号有了这个保证后，在申明三方包依赖时，除了可依赖于一个固定版本号外，还可依赖于某个范围的版本号。例如"argv": "0.0.x"表示依赖于
0.0.x 系列的最新版 argv。NPM 支持的所有版本号范围指定方式可以查看官方文档。

灵机一点

除了本章介绍的部分外，NPM 还提供了很多功能，package.json 里也有很多其它有用的字段。除了可以在 npmjs.org/doc/查看官方文档外，这里再介绍
一些 NPM 常用命令。

  * NPM 提供了很多命令，例如 install 和 publish，使用 npm help 可查看所有命令。
   
  * 使用 npm help <command>可查看某条命令的详细帮助，例如 npm help install。
   
  * 在 package.json 所在目录下使用 npm install . -g 可先在本地安装当前命令行程序，可用于发布前的本地测试。
   
  * 使用 npm update <package>可以把当前目录下 node_modules 子目录里边的对应模块更新至最新版本。
   
  * 使用 npm update <package> -g 可以把全局安装的对应命令行程序更新至最新版。
   
  * 使用 npm cache clear 可以清空 NPM 本地缓存，用于对付使用相同版本号发布新版本代码的人。
   
  * 使用 npm unpublish <package>@<version>可以撤销发布自己发布过的某个版本代码。
   
小结

本章介绍了使用 NodeJS 编写代码前需要做的准备工作，总结起来有以下几点：

  * 编写代码前先规划好目录结构，才能做到有条不紊。
   
  * 稍大些的程序可以将代码拆分为多个模块管理，更大些的程序可以使用包来组织模块。
   
  * 合理使用 node_modules 和 NODE_PATH 来解耦包的使用方式和物理路径。
   
  * 使用 NPM 加入 NodeJS 生态圈互通有无。
   
  * 想到了心仪的包名时请提前在 NPM 上抢注。
   
文件操作

让前端觉得如获神器的不是 NodeJS 能做网络编程，而是 NodeJS 能够操作文件。小至文件查找，大至代码编译，几乎没有一个前端工具不操作文件。换个
角度讲，几乎也只需要一些数据处理逻辑，再加上一些文件操作，就能够编写出大多数前端工具。本章将介绍与之相关的 NodeJS 内置模块。

开门红

NodeJS 提供了基本的文件操作 API，但是像文件拷贝这种高级功能就没有提供，因此我们先拿文件拷贝程序练手。与 copy 命令类似，我们的程序需要能
接受源文件路径与目标文件路径两个参数。

小文件拷贝

我们使用 NodeJS 内置的 fs 模块简单实现这个程序如下。

var fs = require('fs');

function copy(src, dst) {
    fs.writeFileSync(dst, fs.readFileSync(src));
}

function main(argv) {
    copy(argv[0], argv[1]);
}

main(process.argv.slice(2));

以上程序使用 fs.readFileSync 从源路径读取文件内容，并使用 fs.writeFileSync 将文件内容写入目标路径。

    豆知识：process 是一个全局变量，可通过 process.argv 获得命令行参数。由于 argv[0]固定等于 NodeJS 执行程序的绝对路径，argv[1]固定等于主
    模块的绝对路径，因此第一个命令行参数从 argv[2]这个位置开始。
   
大文件拷贝

上边的程序拷贝一些小文件没啥问题，但这种一次性把所有文件内容都读取到内存中后再一次性写入磁盘的方式不适合拷贝大文件，内存会爆仓。对于
大文件，我们只能读一点写一点，直到完成拷贝。因此上边的程序需要改造如下。

var fs = require('fs');

function copy(src, dst) {
    fs.createReadStream(src).pipe(fs.createWriteStream(dst));
}

function main(argv) {
    copy(argv[0], argv[1]);
}

main(process.argv.slice(2));

以上程序使用 fs.createReadStream 创建了一个源文件的只读数据流，并使用 fs.createWriteStream 创建了一个目标文件的只写数据流，并且用 pipe 方
法把两个数据流连接了起来。连接起来后发生的事情，说得抽象点的话，水顺着水管从一个桶流到了另一个桶。

API 走马观花

我们先大致看看 NodeJS 提供了哪些和文件操作有关的 API。这里并不逐一介绍每个 API 的使用方法，官方文档已经做得很好了。

Buffer（数据块）

    官方文档：http://nodejs.org/api/buffer.html
   
JS 语言自身只有字符串数据类型，没有二进制数据类型，因此 NodeJS 提供了一个与 String 对等的全局构造函数 Buffer 来提供对二进制数据的操作。除了
可以读取文件得到 Buffer 的实例外，还能够直接构造，例如：

var bin = new Buffer([ 0x68, 0x65, 0x6c, 0x6c, 0x6f ]);

Buffer 与字符串类似，除了可以用.length 属性得到字节长度外，还可以用[index]方式读取指定位置的字节，例如：

bin[0]; // => 0x68;

Buffer 与字符串能够互相转化，例如可以使用指定编码将二进制数据转化为字符串：

var str = bin.toString('utf-8'); // => "hello"

或者反过来，将字符串转换为指定编码下的二进制数据：

var bin = new Buffer('hello', 'utf-8'); // => <Buffer 68 65 6c 6c 6f>

Buffer 与字符串有一个重要区别。字符串是只读的，并且对字符串的任何修改得到的都是一个新字符串，原字符串保持不变。至于 Buffer，更像是可以
做指针操作的 C 语言数组。例如，可以用[index]方式直接修改某个位置的字节。

bin[0] = 0x48;

而.slice 方法也不是返回一个新的 Buffer，而更像是返回了指向原 Buffer 中间的某个位置的指针，如下所示。

[ 0x68, 0x65, 0x6c, 0x6c, 0x6f ]
    ^           ^
    |           |
   bin     bin.slice(2)

因此对.slice 方法返回的 Buffer 的修改会作用于原 Buffer，例如：

var bin = new Buffer([ 0x68, 0x65, 0x6c, 0x6c, 0x6f ]);
var sub = bin.slice(2);

sub[0] = 0x65;
console.log(bin); // => <Buffer 68 65 65 6c 6f>

也因此，如果想要拷贝一份 Buffer，得首先创建一个新的 Buffer，并通过.copy 方法把原 Buffer 中的数据复制过去。这个类似于申请一块新的内存，并
把已有内存中的数据复制过去。以下是一个例子。

var bin = new Buffer([ 0x68, 0x65, 0x6c, 0x6c, 0x6f ]);
var dup = new Buffer(bin.length);

bin.copy(dup);
dup[0] = 0x48;
console.log(bin); // => <Buffer 68 65 6c 6c 6f>
console.log(dup); // => <Buffer 48 65 65 6c 6f>

总之，Buffer 将 JS 的数据处理能力从字符串扩展到了任意二进制数据。

Stream（数据流）

    官方文档：http://nodejs.org/api/stream.html
   
当内存中无法一次装下需要处理的数据时，或者一边读取一边处理更加高效时，我们就需要用到数据流。NodeJS 中通过各种 Stream 来提供对数据流的操
作。

以上边的大文件拷贝程序为例，我们可以为数据来源创建一个只读数据流，示例如下：

var rs = fs.createReadStream(pathname);

rs.on('data', function (chunk) {
    doSomething(chunk);
});

rs.on('end', function () {
    cleanUp();
});

    豆知识：Stream 基于事件机制工作，所有 Stream 的实例都继承于 NodeJS 提供的 EventEmitter。
   
上边的代码中 data 事件会源源不断地被触发，不管 doSomething 函数是否处理得过来。代码可以继续做如下改造，以解决这个问题。

var rs = fs.createReadStream(src);

rs.on('data', function (chunk) {
    rs.pause();
    doSomething(chunk, function () {
        rs.resume();
    });
});

rs.on('end', function () {
    cleanUp();
});

以上代码给 doSomething 函数加上了回调，因此我们可以在处理数据前暂停数据读取，并在处理数据后继续读取数据。

此外，我们也可以为数据目标创建一个只写数据流，示例如下：

var rs = fs.createReadStream(src);
var ws = fs.createWriteStream(dst);

rs.on('data', function (chunk) {
    ws.write(chunk);
});

rs.on('end', function () {
    ws.end();
});

我们把 doSomething 换成了往只写数据流里写入数据后，以上代码看起来就像是一个文件拷贝程序了。但是以上代码存在上边提到的问题，如果写入速
度跟不上读取速度的话，只写数据流内部的缓存会爆仓。我们可以根据.write 方法的返回值来判断传入的数据是写入目标了，还是临时放在了缓存了，
并根据 drain 事件来判断什么时候只写数据流已经将缓存中的数据写入目标，可以传入下一个待写数据了。因此代码可以改造如下：

var rs = fs.createReadStream(src);
var ws = fs.createWriteStream(dst);

rs.on('data', function (chunk) {
    if (ws.write(chunk) === false) {
        rs.pause();
    }
});

rs.on('end', function () {
    ws.end();
});

ws.on('drain', function () {
    rs.resume();
});

以上代码实现了数据从只读数据流到只写数据流的搬运，并包括了防爆仓控制。因为这种使用场景很多，例如上边的大文件拷贝程序，NodeJS 直接提供
了.pipe 方法来做这件事情，其内部实现方式与上边的代码类似。

File System（文件系统）

    官方文档：http://nodejs.org/api/fs.html
   
NodeJS 通过 fs 内置模块提供对文件的操作。fs 模块提供的 API 基本上可以分为以下三类：

  * 文件属性读写。
   
    其中常用的有 fs.stat、fs.chmod、fs.chown 等等。
   
  * 文件内容读写。
   
    其中常用的有 fs.readFile、fs.readdir、fs.writeFile、fs.mkdir 等等。
   
  * 底层文件操作。
   
    其中常用的有 fs.open、fs.read、fs.write、fs.close 等等。
   
NodeJS 最精华的异步 IO 模型在 fs 模块里有着充分的体现，例如上边提到的这些 API 都通过回调函数传递结果。以 fs.readFile 为例：

fs.readFile(pathname, function (err, data) {
    if (err) {
        // Deal with error.
    } else {
        // Deal with data.
    }
});

如上边代码所示，基本上所有 fs 模块 API 的回调参数都有两个。第一个参数在有错误发生时等于异常对象，第二个参数始终用于返回 API 方法执行结果。

此外，fs 模块的所有异步 API 都有对应的同步版本，用于无法使用异步操作时，或者同步操作更方便时的情况。同步 API 除了方法名的末尾多了一个 Sync
之外，异常对象与执行结果的传递方式也有相应变化。同样以 fs.readFileSync 为例：

try {
    var data = fs.readFileSync(pathname);
    // Deal with data.
} catch (err) {
    // Deal with error.
}

fs 模块提供的 API 很多，这里不一一介绍，需要时请自行查阅官方文档。

Path（路径）

    官方文档：http://nodejs.org/api/path.html
   
操作文件时难免不与文件路径打交道。NodeJS 提供了 path 内置模块来简化路径相关操作，并提升代码可读性。以下分别介绍几个常用的 API。

  * path.normalize
   
    将传入的路径转换为标准路径，具体讲的话，除了解析路径中的.与..外，还能去掉多余的斜杠。如果有程序需要使用路径作为某些数据的索引，
    但又允许用户随意输入路径时，就需要使用该方法保证路径的唯一性。以下是一个例子：
   
      var cache = {};
    
      function store(key, value) {
          cache[path.normalize(key)] = value;
      }
    
      store('foo/bar', 1);
      store('foo//baz//../bar', 2);
      console.log(cache);  // => { "foo/bar": 2 }
    
        坑出没注意：标准化之后的路径里的斜杠在 Windows 系统下是\，而在 Linux 系统下是/。如果想保证任何系统下都使用/作为路径分隔符的话，
        需要用.replace(/\\/g, '/')再替换一下标准路径。
       
  * path.join
   
    将传入的多个路径拼接为标准路径。该方法可避免手工拼接路径字符串的繁琐，并且能在不同系统下正确使用相应的路径分隔符。以下是一个例子
    ：
   
      path.join('foo/', 'baz/', '../bar'); // => "foo/bar"
    
  * path.extname
   
    当我们需要根据不同文件扩展名做不同操作时，该方法就显得很好用。以下是一个例子：
   
      path.extname('foo/bar.js'); // => ".js"
    
path 模块提供的其余方法也不多，稍微看一下官方文档就能全部掌握。

遍历目录

遍历目录是操作文件时的一个常见需求。比如写一个程序，需要找到并处理指定目录下的所有 JS 文件时，就需要遍历整个目录。

递归算法

遍历目录时一般使用递归算法，否则就难以编写出简洁的代码。递归算法与数学归纳法类似，通过不断缩小问题的规模来解决问题。以下示例说明了这
种方法。

function factorial(n) {
    if (n === 1) {
        return 1;
    } else {
        return n * factorial(n - 1);
    }
}

上边的函数用于计算 N 的阶乘（N!）。可以看到，当 N 大于 1 时，问题简化为计算 N 乘以 N-1 的阶乘。当 N 等于 1 时，问题达到最小规模，不需要再简化，因
此直接返回 1。

    陷阱：使用递归算法编写的代码虽然简洁，但由于每递归一次就产生一次函数调用，在需要优先考虑性能时，需要把递归算法转换为循环算法，以
    减少函数调用次数。
   
遍历算法

目录是一个树状结构，在遍历时一般使用深度优先+先序遍历算法。深度优先，意味着到达一个节点后，首先接着遍历子节点而不是邻居节点。先序遍
历，意味着首次到达了某节点就算遍历完成，而不是最后一次返回某节点才算数。因此使用这种遍历方式时，下边这棵树的遍历顺序是 A > B > D > E
> C > F。

          A
         / \
        B   C
       / \   \
      D   E   F

同步遍历

了解了必要的算法后，我们可以简单地实现以下目录遍历函数。

function travel(dir, callback) {
    fs.readdirSync(dir).forEach(function (file) {
        var pathname = path.join(dir, file);

        if (fs.statSync(pathname).isDirectory()) {
            travel(pathname, callback);
        } else {
            callback(pathname);
        }
    });
}

可以看到，该函数以某个目录作为遍历的起点。遇到一个子目录时，就先接着遍历子目录。遇到一个文件时，就把文件的绝对路径传给回调函数。回调
函数拿到文件路径后，就可以做各种判断和处理。因此假设有以下目录：

- /home/user/
    - foo/
        x.js
    - bar/
        y.js
    z.css

使用以下代码遍历该目录时，得到的输入如下。

travel('/home/user', function (pathname) {
    console.log(pathname);
});

------------------------
/home/user/foo/x.js
/home/user/bar/y.js
/home/user/z.css

异步遍历

如果读取目录或读取文件状态时使用的是异步 API，目录遍历函数实现起来会有些复杂，但原理完全相同。travel 函数的异步版本如下。

function travel(dir, callback, finish) {
    fs.readdir(dir, function (err, files) {
        (function next(i) {
            if (i < files.length) {
                var pathname = path.join(dir, files[i]);

                fs.stat(pathname, function (err, stats) {
                    if (stats.isDirectory()) {
                        travel(pathname, callback, function () {
                            next(i + 1);
                        });
                    } else {
                        callback(pathname, function () {
                            next(i + 1);
                        });
                    }
                });
            } else {
                finish && finish();
            }
        }(0));
    });
}

这里不详细介绍异步遍历函数的编写技巧，在后续章节中会详细介绍这个。总之我们可以看到异步编程还是蛮复杂的。

文本编码

使用 NodeJS 编写前端工具时，操作得最多的是文本文件，因此也就涉及到了文件编码的处理问题。我们常用的文本编码有 UTF8 和 GBK 两种，并且 UTF8 文
件还可能带有 BOM。在读取不同编码的文本文件时，需要将文件内容转换为 JS 使用的 UTF8 编码字符串后才能正常处理。

BOM 的移除

BOM 用于标记一个文本文件使用 Unicode 编码，其本身是一个 Unicode 字符（"\uFEFF"），位于文本文件头部。在不同的 Unicode 编码下，BOM 字符对应的
二进制字节如下：

    Bytes      Encoding
----------------------------
    FE FF       UTF16BE
    FF FE       UTF16LE
    EF BB BF    UTF8

因此，我们可以根据文本文件头几个字节等于啥来判断文件是否包含 BOM，以及使用哪种 Unicode 编码。但是，BOM 字符虽然起到了标记文件编码的作用
，其本身却不属于文件内容的一部分，如果读取文本文件时不去掉 BOM，在某些使用场景下就会有问题。例如我们把几个 JS 文件合并成一个文件后，如
果文件中间含有 BOM 字符，就会导致浏览器 JS 语法错误。因此，使用 NodeJS 读取文本文件时，一般需要去掉 BOM。例如，以下代码实现了识别和去除 UTF8
BOM 的功能。

function readText(pathname) {
    var bin = fs.readFileSync(pathname);

    if (bin[0] === 0xEF && bin[1] === 0xBB && bin[2] === 0xBF) {
        bin = bin.slice(3);
    }

    return bin.toString('utf-8');
}

GBK 转 UTF8

NodeJS 支持在读取文本文件时，或者在 Buffer 转换为字符串时指定文本编码，但遗憾的是，GBK 编码不在 NodeJS 自身支持范围内。因此，一般我们借助
iconv-lite 这个三方包来转换编码。使用 NPM 下载该包后，我们可以按下边方式编写一个读取 GBK 文本文件的函数。

var iconv = require('iconv-lite');

function readGBKText(pathname) {
    var bin = fs.readFileSync(pathname);

    return iconv.decode(bin, 'gbk');
}

单字节编码

有时候，我们无法预知需要读取的文件采用哪种编码，因此也就无法指定正确的编码。比如我们要处理的某些 CSS 文件中，有的用 GBK 编码，有的用 UTF8
编码。虽然可以一定程度可以根据文件的字节内容猜测出文本编码，但这里要介绍的是有些局限，但是要简单得多的一种技术。

首先我们知道，如果一个文本文件只包含英文字符，比如 Hello World，那无论用 GBK 编码或是 UTF8 编码读取这个文件都是没问题的。这是因为在这些编
码下，ASCII0~128 范围内字符都使用相同的单字节编码。

反过来讲，即使一个文本文件中有中文等字符，如果我们需要处理的字符仅在 ASCII0~128 范围内，比如除了注释和字符串以外的 JS 代码，我们就可以统
一使用单字节编码来读取文件，不用关心文件的实际编码是 GBK 还是 UTF8。以下示例说明了这种方法。

1. GBK 编码源文件内容：
    var foo = '中文';
2. 对应字节：
    76 61 72 20 66 6F 6F 20 3D 20 27 D6 D0 CE C4 27 3B
3. 使用单字节编码读取后得到的内容：
    var foo = '{乱码}{乱码}{乱码}{乱码}';
4. 替换内容：
    var bar = '{乱码}{乱码}{乱码}{乱码}';
5. 使用单字节编码保存后对应字节：
    76 61 72 20 62 61 72 20 3D 20 27 D6 D0 CE C4 27 3B
6. 使用 GBK 编码读取后得到内容：
    var bar = '中文';

这里的诀窍在于，不管大于 0xEF 的单个字节在单字节编码下被解析成什么乱码字符，使用同样的单字节编码保存这些乱码字符时，背后对应的字节保持
不变。

NodeJS 中自带了一种 binary 编码可以用来实现这个方法，因此在下例中，我们使用这种编码来演示上例对应的代码该怎么写。

function replace(pathname) {
    var str = fs.readFileSync(pathname, 'binary');
    str = str.replace('foo', 'bar');
    fs.writeFileSync(pathname, str, 'binary');
}

小结

本章介绍了使用 NodeJS 操作文件时需要的 API 以及一些技巧，总结起来有以下几点：

  * 学好文件操作，编写各种程序都不怕。
   
  * 如果不是很在意性能，fs 模块的同步 API 能让生活更加美好。
   
  * 需要对文件读写做到字节级别的精细控制时，请使用 fs 模块的文件底层操作 API。
   
  * 不要使用拼接字符串的方式来处理路径，使用 path 模块。
   
  * 掌握好目录遍历和文件编码处理技巧，很实用。
   
网络操作

不了解网络编程的程序员不是好前端，而 NodeJS 恰好提供了一扇了解网络编程的窗口。通过 NodeJS，除了可以编写一些服务端程序来协助前端开发和测
试外，还能够学习一些 HTTP 协议与 Socket 协议的相关知识，这些知识在优化前端性能和排查前端故障时说不定能派上用场。本章将介绍与之相关的
NodeJS 内置模块。

开门红

NodeJS 本来的用途是编写高性能 Web 服务器。我们首先在这里重复一下官方文档里的例子，使用 NodeJS 内置的 http 模块简单实现一个 HTTP 服务器。

var http = require('http');

http.createServer(function (request, response) {
    response.writeHead(200, { 'Content-Type': 'text-plain' });
    response.end('Hello World\n');
}).listen(8124);

以上程序创建了一个 HTTP 服务器并监听 8124 端口，打开浏览器访问该端口 http://127.0.0.1:8124/就能够看到效果。

    豆知识：在 Linux 系统下，监听 1024 以下端口需要 root 权限。因此，如果想监听 80 或 443 端口的话，需要使用 sudo 命令启动程序。
   
API 走马观花

我们先大致看看 NodeJS 提供了哪些和网络操作有关的 API。这里并不逐一介绍每个 API 的使用方法，官方文档已经做得很好了。

HTTP

    官方文档：http://nodejs.org/api/http.html
   
'http'模块提供两种使用方式：

  * 作为服务端使用时，创建一个 HTTP 服务器，监听 HTTP 客户端请求并返回响应。
   
  * 作为客户端使用时，发起一个 HTTP 客户端请求，获取服务端响应。
   
首先我们来看看服务端模式下如何工作。如开门红中的例子所示，首先需要使用.createServer 方法创建一个服务器，然后调用.listen 方法监听端口。
之后，每当来了一个客户端请求，创建服务器时传入的回调函数就被调用一次。可以看出，这是一种事件机制。

HTTP 请求本质上是一个数据流，由请求头（headers）和请求体（body）组成。例如以下是一个完整的 HTTP 请求数据内容。

POST / HTTP/1.1
User-Agent: curl/7.26.0
Host: localhost
Accept: */*
Content-Length: 11
Content-Type: application/x-www-form-urlencoded

Hello World

可以看到，空行之上是请求头，之下是请求体。HTTP 请求在发送给服务器时，可以认为是按照从头到尾的顺序一个字节一个字节地以数据流方式发送的
。而 http 模块创建的 HTTP 服务器在接收到完整的请求头后，就会调用回调函数。在回调函数中，除了可以使用 request 对象访问请求头数据外，还能把
request 对象当作一个只读数据流来访问请求体数据。以下是一个例子。

http.createServer(function (request, response) {
    var body = [];

    console.log(request.method);
    console.log(request.headers);

    request.on('data', function (chunk) {
        body.push(chunk);
    });

    request.on('end', function () {
        body = Buffer.concat(body);
        console.log(body.toString());
    });
}).listen(80);

------------------------------------
POST
{ 'user-agent': 'curl/7.26.0',
  host: 'localhost',
  accept: '*/*',
  'content-length': '11',
  'content-type': 'application/x-www-form-urlencoded' }
Hello World

HTTP 响应本质上也是一个数据流，同样由响应头（headers）和响应体（body）组成。例如以下是一个完整的 HTTP 请求数据内容。

HTTP/1.1 200 OK
Content-Type: text/plain
Content-Length: 11
Date: Tue, 05 Nov 2013 05:31:38 GMT
Connection: keep-alive

Hello World

在回调函数中，除了可以使用 response 对象来写入响应头数据外，还能把 response 对象当作一个只写数据流来写入响应体数据。例如在以下例子中，服
务端原样将客户端请求的请求体数据返回给客户端。

http.createServer(function (request, response) {
    response.writeHead(200, { 'Content-Type': 'text/plain' });

    request.on('data', function (chunk) {
        response.write(chunk);
    });

    request.on('end', function () {
        response.end();
    });
}).listen(80);

接下来我们看看客户端模式下如何工作。为了发起一个客户端 HTTP 请求，我们需要指定目标服务器的位置并发送请求头和请求体，以下示例演示了具体
做法。

var options = {
        hostname: 'www.example.com';,
        port: 80,
        path: '/upload',
        method: 'POST',
        headers: {
            'Content-Type': 'application/x-www-form-urlencoded'
        }
    };

var request = http.request(options, function (response) {});

request.write('Hello World');
request.end();

可以看到，.request 方法创建了一个客户端，并指定请求目标和请求头数据。之后，就可以把 request 对象当作一个只写数据流来写入请求体数据和结
束请求。另外，由于 HTTP 请求中 GET 请求是最常见的一种，并且不需要请求体，因此 http 模块也提供了以下便捷 API。

http.get('http://www.example.com/';, function (response) {});

当客户端发送请求并接收到完整的服务端响应头时，就会调用回调函数。在回调函数中，除了可以使用 response 对象访问响应头数据外，还能把
response 对象当作一个只读数据流来访问响应体数据。以下是一个例子。

http.get('http://www.example.com/';, function (response) {
    var body = [];

    console.log(response.statusCode);
    console.log(response.headers);

    response.on('data', function (chunk) {
        body.push(chunk);
    });

    response.on('end', function () {
        body = Buffer.concat(body);
        console.log(body.toString());
    });
});

------------------------------------
200
{ 'content-type': 'text/html',
  server: 'Apache',
  'content-length': '801',
  date: 'Tue, 05 Nov 2013 06:08:41 GMT',
  connection: 'keep-alive' }
<!DOCTYPE html>
...

HTTPS

    官方文档：http://nodejs.org/api/https.html
   
https 模块与 http 模块极为类似，区别在于 https 模块需要额外处理 SSL 证书。

在服务端模式下，创建一个 HTTPS 服务器的示例如下。

var options = {
        key: fs.readFileSync('./ssl/default.key'),
        cert: fs.readFileSync('./ssl/default.cer')
    };

var server = https.createServer(options, function (request, response) {
        // ...
    });

可以看到，与创建 HTTP 服务器相比，多了一个 options 对象，通过 key 和 cert 字段指定了 HTTPS 服务器使用的私钥和公钥。

另外，NodeJS 支持 SNI 技术，可以根据 HTTPS 客户端请求使用的域名动态使用不同的证书，因此同一个 HTTPS 服务器可以使用多个域名提供服务。接着上
例，可以使用以下方法为 HTTPS 服务器添加多组证书。

server.addContext('foo.com', {
    key: fs.readFileSync('./ssl/foo.com.key'),
    cert: fs.readFileSync('./ssl/foo.com.cer')
});

server.addContext('bar.com', {
    key: fs.readFileSync('./ssl/bar.com.key'),
    cert: fs.readFileSync('./ssl/bar.com.cer')
});

在客户端模式下，发起一个 HTTPS 客户端请求与 http 模块几乎相同，示例如下。

var options = {
        hostname: 'www.example.com';,
        port: 443,
        path: '/',
        method: 'GET'
    };

var request = https.request(options, function (response) {});

request.end();

但如果目标服务器使用的 SSL 证书是自制的，不是从颁发机构购买的，默认情况下 https 模块会拒绝连接，提示说有证书安全问题。在 options 里加入
rejectUnauthorized: false 字段可以禁用对证书有效性的检查，从而允许 https 模块请求开发环境下使用自制证书的 HTTPS 服务器。

URL

    官方文档：http://nodejs.org/api/url.html
   
处理 HTTP 请求时 url 模块使用率超高，因为该模块允许解析 URL、生成 URL，以及拼接 URL。首先我们来看看一个完整的 URL 的各组成部分。

                           href
 -----------------------------------------------------------------
                            host              path
                      --------------- ----------------------------
 http: // user:pass @ host.com : 8080 /p/a/t/h ?query=string #hash
 -----    ---------   --------   ---- -------- ------------- -----
protocol     auth     hostname   port pathname     search     hash
                                                ------------
                                                   query

我们可以使用.parse 方法来将一个 URL 字符串转换为 URL 对象，示例如下。

url.parse('http://user:pass@host.com:8080/p/a/t/h?query=string#hash';);
/* =>
{ protocol: 'http:';,
  auth: 'user:pass',
  host: 'host.com:8080',
  port: '8080',
  hostname: 'host.com',
  hash: '#hash',
  search: '?query=string',
  query: 'query=string',
  pathname: '/p/a/t/h',
  path: '/p/a/t/h?query=string',
  href: 'http://user:pass@host.com:8080/p/a/t/h?query=string#hash'; }
*/

传给.parse 方法的不一定要是一个完整的 URL，例如在 HTTP 服务器回调函数中，request.url 不包含协议头和域名，但同样可以用.parse 方法解析。

http.createServer(function (request, response) {
    var tmp = request.url; // => "/foo/bar?a=b"
    url.parse(tmp);
    /* =>
    { protocol: null,
      slashes: null,
      auth: null,
      host: null,
      port: null,
      hostname: null,
      hash: null,
      search: '?a=b',
      query: 'a=b',
      pathname: '/foo/bar',
      path: '/foo/bar?a=b',
      href: '/foo/bar?a=b' }
    */
}).listen(80);

.parse 方法还支持第二个和第三个布尔类型可选参数。第二个参数等于 true 时，该方法返回的 URL 对象中，query 字段不再是一个字符串，而是一个经过
querystring 模块转换后的参数对象。第三个参数等于 true 时，该方法可以正确解析不带协议头的 URL，例如//www.example.com/foo/bar。

反过来，format 方法允许将一个 URL 对象转换为 URL 字符串，示例如下。

url.format({
    protocol: 'http:';,
    host: 'www.example.com';,
    pathname: '/p/a/t/h',
    search: 'query=string'
});
/* =>
'http://www.example.com/p/a/t/h?query=string';
*/

另外，.resolve 方法可以用于拼接 URL，示例如下。

url.resolve('http://www.example.com/foo/bar';, '../baz');
/* =>
http://www.example.com/baz
*/

Query String

    官方文档：http://nodejs.org/api/querystring.html
   
querystring 模块用于实现 URL 参数字符串与参数对象的互相转换，示例如下。

querystring.parse('foo=bar&baz=qux&baz=quux&corge');
/* =>
{ foo: 'bar', baz: ['qux', 'quux'], corge: '' }
*/

querystring.stringify({ foo: 'bar', baz: ['qux', 'quux'], corge: '' });
/* =>
'foo=bar&baz=qux&baz=quux&corge='
*/

Zlib

    官方文档：http://nodejs.org/api/zlib.html
   
zlib 模块提供了数据压缩和解压的功能。当我们处理 HTTP 请求和响应时，可能需要用到这个模块。

首先我们看一个使用 zlib 模块压缩 HTTP 响应体数据的例子。这个例子中，判断了客户端是否支持 gzip，并在支持的情况下使用 zlib 模块返回 gzip 之后的
响应体数据。

http.createServer(function (request, response) {
    var i = 1024,
        data = '';

    while (i--) {
        data += '.';
    }

    if ((request.headers['accept-encoding'] || '').indexOf('gzip') !== -1) {
        zlib.gzip(data, function (err, data) {
            response.writeHead(200, {
                'Content-Type': 'text/plain',
                'Content-Encoding': 'gzip'
            });
            response.end(data);
        });
    } else {
        response.writeHead(200, {
            'Content-Type': 'text/plain'
        });
        response.end(data);
    }
}).listen(80);

接着我们看一个使用 zlib 模块解压 HTTP 响应体数据的例子。这个例子中，判断了服务端响应是否使用 gzip 压缩，并在压缩的情况下使用 zlib 模块解压响
应体数据。

var options = {
        hostname: 'www.example.com';,
        port: 80,
        path: '/',
        method: 'GET',
        headers: {
            'Accept-Encoding': 'gzip, deflate'
        }
    };

http.request(options, function (response) {
    var body = [];

    response.on('data', function (chunk) {
        body.push(chunk);
    });

    response.on('end', function () {
        body = Buffer.concat(body);

        if (response.headers['content-encoding'] === 'gzip') {
            zlib.gunzip(body, function (err, data) {
                console.log(data.toString());
            });
        } else {
            console.log(data.toString());
        }
    });
}).end();

Net

    官方文档：http://nodejs.org/api/net.html
   
net 模块可用于创建 Socket 服务器或 Socket 客户端。由于 Socket 在前端领域的使用范围还不是很广，这里先不涉及到 WebSocket 的介绍，仅仅简单演示一
下如何从 Socket 层面来实现 HTTP 请求和响应。

首先我们来看一个使用 Socket 搭建一个很不严谨的 HTTP 服务器的例子。这个 HTTP 服务器不管收到啥请求，都固定返回相同的响应。

net.createServer(function (conn) {
    conn.on('data', function (data) {
        conn.write([
            'HTTP/1.1 200 OK',
            'Content-Type: text/plain',
            'Content-Length: 11',
            '',
            'Hello World'
        ].join('\n'));
    });
}).listen(80);

接着我们来看一个使用 Socket 发起 HTTP 客户端请求的例子。这个例子中，Socket 客户端在建立连接后发送了一个 HTTP GET 请求，并通过 data 事件监听函
数来获取服务器响应。

var options = {
        port: 80,
        host: 'www.example.com';
    };

var client = net.connect(options, function () {
        client.write([
            'GET / HTTP/1.1',
            'User-Agent: curl/7.26.0',
            'Host: www.baidu.com';,
            'Accept: */*',
            '',
            ''
        ].join('\n'));
    });

client.on('data', function (data) {
    console.log(data.toString());
    client.end();
});

灵机一点

使用 NodeJS 操作网络，特别是操作 HTTP 请求和响应时会遇到一些惊喜，这里对一些常见问题做解答。

  * 问：为什么通过 headers 对象访问到的 HTTP 请求头或响应头字段不是驼峰的？
   
    答：从规范上讲，HTTP 请求头和响应头字段都应该是驼峰的。但现实是残酷的，不是每个 HTTP 服务端或客户端程序都严格遵循规范，所以 NodeJS 在
    处理从别的客户端或服务端收到的头字段时，都统一地转换为了小写字母格式，以便开发者能使用统一的方式来访问头字段，例如 headers
    ['content-length']。
   
  * 问：为什么 http 模块创建的 HTTP 服务器返回的响应是 chunked 传输方式的？
   
    答：因为默认情况下，使用.writeHead 方法写入响应头后，允许使用.write 方法写入任意长度的响应体数据，并使用.end 方法结束一个响应。由于
    响应体数据长度不确定，因此 NodeJS 自动在响应头里添加了 Transfer-Encoding: chunked 字段，并采用 chunked 传输方式。但是当响应体数据长度
    确定时，可使用.writeHead 方法在响应头里加上 Content-Length 字段，这样做之后 NodeJS 就不会自动添加 Transfer-Encoding 字段和使用 chunked 传
    输方式。
   
  * 问：为什么使用 http 模块发起 HTTP 客户端请求时，有时候会发生 socket hang up 错误？
   
    答：发起客户端 HTTP 请求前需要先创建一个客户端。http 模块提供了一个全局客户端 http.globalAgent，可以让我们使用.request 或.get 方法时不
    用手动创建客户端。但是全局客户端默认只允许 5 个并发 Socket 连接，当某一个时刻 HTTP 客户端请求创建过多，超过这个数字时，就会发生 socket
    hang up 错误。解决方法也很简单，通过 http.globalAgent.maxSockets 属性把这个数字改大些即可。另外，https 模块遇到这个问题时也一样通过
    https.globalAgent.maxSockets 属性来处理。
   
小结

本章介绍了使用 NodeJS 操作网络时需要的 API 以及一些坑回避技巧，总结起来有以下几点：

  * http 和 https 模块支持服务端模式和客户端模式两种使用方式。
   
  * request 和 response 对象除了用于读写头数据外，都可以当作数据流来操作。
   
  * url.parse 方法加上 request.url 属性是处理 HTTP 请求时的固定搭配。
   
  * 使用 zlib 模块可以减少使用 HTTP 协议时的数据传输量。
   
  * 通过 net 模块的 Socket 服务器与客户端可对 HTTP 协议做底层操作。
   
  * 小心踩坑。
   
进程管理

NodeJS 可以感知和控制自身进程的运行环境和状态，也可以创建子进程并与其协同工作，这使得 NodeJS 可以把多个程序组合在一起共同完成某项工作，
并在其中充当胶水和调度器的作用。本章除了介绍与之相关的 NodeJS 内置模块外，还会重点介绍典型的使用场景。

开门红

我们已经知道了 NodeJS 自带的 fs 模块比较基础，把一个目录里的所有文件和子目录都拷贝到另一个目录里需要写不少代码。另外我们也知道，终端下的
cp 命令比较好用，一条 cp -r source/* target 命令就能搞定目录拷贝。那我们首先看看如何使用 NodeJS 调用终端命令来简化目录拷贝，示例代码如下
：

var child_process = require('child_process');
var util = require('util');

function copy(source, target, callback) {
    child_process.exec(
        util.format('cp -r %s/* %s', source, target), callback);
}

copy('a', 'b', function (err) {
    // ...
});

从以上代码中可以看到，子进程是异步运行的，通过回调函数返回执行结果。

API 走马观花

我们先大致看看 NodeJS 提供了哪些和进程管理有关的 API。这里并不逐一介绍每个 API 的使用方法，官方文档已经做得很好了。

Process

    官方文档：http://nodejs.org/api/process.html
   
任何一个进程都有启动进程时使用的命令行参数，有标准输入标准输出，有运行权限，有运行环境和运行状态。在 NodeJS 中，可以通过 process 对象感
知和控制 NodeJS 自身进程的方方面面。另外需要注意的是，process 不是内置模块，而是一个全局对象，因此在任何地方都可以直接使用。

Child Process

    官方文档：http://nodejs.org/api/child_process.html
   
使用 child_process 模块可以创建和控制子进程。该模块提供的 API 中最核心的是.spawn，其余 API 都是针对特定使用场景对它的进一步封装，算是一种
语法糖。

Cluster

    官方文档：http://nodejs.org/api/cluster.html
   
cluster 模块是对 child_process 模块的进一步封装，专用于解决单进程 NodeJS Web 服务器无法充分利用多核 CPU 的问题。使用该模块可以简化多进程服
务器程序的开发，让每个核上运行一个工作进程，并统一通过主进程监听端口和分发请求。

应用场景

和进程管理相关的 API 单独介绍起来比较枯燥，因此这里从一些典型的应用场景出发，分别介绍一些重要 API 的使用方法。

如何获取命令行参数

在 NodeJS 中可以通过 process.argv 获取命令行参数。但是比较意外的是，node 执行程序路径和主模块文件路径固定占据了 argv[0]和 argv[1]两个位置，
而第一个命令行参数从 argv[2]开始。为了让 argv 使用起来更加自然，可以按照以下方式处理。

function main(argv) {
    // ...
}

main(process.argv.slice(2));

如何退出程序

通常一个程序做完所有事情后就正常退出了，这时程序的退出状态码为 0。或者一个程序运行时发生了异常后就挂了，这时程序的退出状态码不等于 0。
如果我们在代码中捕获了某个异常，但是觉得程序不应该继续运行下去，需要立即退出，并且需要把退出状态码设置为指定数字，比如 1，就可以按照
以下方式：

try {
    // ...
} catch (err) {
    // ...
    process.exit(1);
}

如何控制输入输出

NodeJS 程序的标准输入流（stdin）、一个标准输出流（stdout）、一个标准错误流（stderr）分别对应 process.stdin、process.stdout 和
process.stderr，第一个是只读数据流，后边两个是只写数据流，对它们的操作按照对数据流的操作方式即可。例如，console.log 可以按照以下方式
实现。

function log() {
    process.stdout.write(
        util.format.apply(util, arguments) + '\n');
}

如何降权

在 Linux 系统下，我们知道需要使用 root 权限才能监听 1024 以下端口。但是一旦完成端口监听后，继续让程序运行在 root 权限下存在安全隐患，因此最
好能把权限降下来。以下是这样一个例子。

http.createServer(callback).listen(80, function () {
    var env = process.env,
        uid = parseInt(env['SUDO_UID'] || process.getuid(), 10),
        gid = parseInt(env['SUDO_GID'] || process.getgid(), 10);

    process.setgid(gid);
    process.setuid(uid);
});

上例中有几点需要注意：

 1. 如果是通过 sudo 获取 root 权限的，运行程序的用户的 UID 和 GID 保存在环境变量 SUDO_UID 和 SUDO_GID 里边。如果是通过 chmod +s 方式获取 root 权限的
    ，运行程序的用户的 UID 和 GID 可直接通过 process.getuid 和 process.getgid 方法获取。
   
 2. process.setuid 和 process.setgid 方法只接受 number 类型的参数。
   
 3. 降权时必须先降 GID 再降 UID，否则顺序反过来的话就没权限更改程序的 GID 了。
   
如何创建子进程

以下是一个创建 NodeJS 子进程的例子。

var child = child_process.spawn('node', [ 'xxx.js' ]);

child.stdout.on('data', function (data) {
    console.log('stdout: ' + data);
});

child.stderr.on('data', function (data) {
    console.log('stderr: ' + data);
});

child.on('close', function (code) {
    console.log('child process exited with code ' + code);
});

上例中使用了.spawn(exec, args, options)方法，该方法支持三个参数。第一个参数是执行文件路径，可以是执行文件的相对或绝对路径，也可以是
根据 PATH 环境变量能找到的执行文件名。第二个参数中，数组中的每个成员都按顺序对应一个命令行参数。第三个参数可选，用于配置子进程的执行环
境与行为。

另外，上例中虽然通过子进程对象的.stdout 和.stderr 访问子进程的输出，但通过 options.stdio 字段的不同配置，可以将子进程的输入输出重定向到
任何数据流上，或者让子进程共享父进程的标准输入输出流，或者直接忽略子进程的输入输出。

进程间如何通讯

在 Linux 系统下，进程之间可以通过信号互相通信。以下是一个例子。

/* parent.js */
var child = child_process.spawn('node', [ 'child.js' ]);

child.kill('SIGTERM');

/* child.js */
process.on('SIGTERM', function () {
    cleanUp();
    process.exit(0);
});

在上例中，父进程通过.kill 方法向子进程发送 SIGTERM 信号，子进程监听 process 对象的 SIGTERM 事件响应信号。不要被.kill 方法的名称迷惑了，该方
法本质上是用来给进程发送信号的，进程收到信号后具体要做啥，完全取决于信号的种类和进程自身的代码。

另外，如果父子进程都是 NodeJS 进程，就可以通过 IPC（进程间通讯）双向传递数据。以下是一个例子。

/* parent.js */
var child = child_process.spawn('node', [ 'child.js' ], {
        stdio: [ 0, 1, 2, 'ipc' ]
    });

child.on('message', function (msg) {
    console.log(msg);
});

child.send({ hello: 'hello' });

/* child.js */
process.on('message', function (msg) {
    msg.hello = msg.hello.toUpperCase();
    process.send(msg);
});

可以看到，父进程在创建子进程时，在 options.stdio 字段中通过 ipc 开启了一条 IPC 通道，之后就可以监听子进程对象的 message 事件接收来自子进程的
消息，并通过.send 方法给子进程发送消息。在子进程这边，可以在 process 对象上监听 message 事件接收来自父进程的消息，并通过.send 方法向父进程
发送消息。数据在传递过程中，会先在发送端使用 JSON.stringify 方法序列化，再在接收端使用 JSON.parse 方法反序列化。

如何守护子进程

守护进程一般用于监控工作进程的运行状态，在工作进程不正常退出时重启工作进程，保障工作进程不间断运行。以下是一种实现方式。

/* daemon.js */
function spawn(mainModule) {
    var worker = child_process.spawn('node', [ mainModule ]);

    worker.on('exit', function (code) {
        if (code !== 0) {
            spawn(mainModule);
        }
    });
}

spawn('worker.js');

可以看到，工作进程非正常退出时，守护进程立即重启工作进程。

小结

本章介绍了使用 NodeJS 管理进程时需要的 API 以及主要的应用场景，总结起来有以下几点：

  * 使用 process 对象管理自身。
   
  * 使用 child_process 模块创建和管理子进程。
   
异步编程

NodeJS 最大的卖点——事件机制和异步 IO，对开发者并不是透明的。开发者需要按异步方式编写代码才用得上这个卖点，而这一点也遭到了一些 NodeJS 反
对者的抨击。但不管怎样，异步编程确实是 NodeJS 最大的特点，没有掌握异步编程就不能说是真正学会了 NodeJS。本章将介绍与异步编程相关的各种知
识。

回调

在代码中，异步编程的直接体现就是回调。异步编程依托于回调来实现，但不能说使用了回调后程序就异步化了。我们首先可以看看以下代码。

function heavyCompute(n, callback) {
    var count = 0,
        i, j;

    for (i = n; i > 0; --i) {
        for (j = n; j > 0; --j) {
            count += 1;
        }
    }

    callback(count);
}

heavyCompute(10000, function (count) {
    console.log(count);
});

console.log('hello');

-- Console ------------------------------
100000000
hello

可以看到，以上代码中的回调函数仍然先于后续代码执行。JS 本身是单线程运行的，不可能在一段代码还未结束运行时去运行别的代码，因此也就不存
在异步执行的概念。

但是，如果某个函数做的事情是创建一个别的线程或进程，并与 JS 主线程并行地做一些事情，并在事情做完后通知 JS 主线程，那情况又不一样了。我们
接着看看以下代码。

setTimeout(function () {
    console.log('world');
}, 1000);

console.log('hello');

-- Console ------------------------------
hello
world

这次可以看到，回调函数后于后续代码执行了。如同上边所说，JS 本身是单线程的，无法异步执行，因此我们可以认为 setTimeout 这类 JS 规范之外的由
运行环境提供的特殊函数做的事情是创建一个平行线程后立即返回，让 JS 主进程可以接着执行后续代码，并在收到平行进程的通知后再执行回调函数。
除了 setTimeout、setInterval 这些常见的，这类函数还包括 NodeJS 提供的诸如 fs.readFile 之类的异步 API。

另外，我们仍然回到 JS 是单线程运行的这个事实上，这决定了 JS 在执行完一段代码之前无法执行包括回调函数在内的别的代码。也就是说，即使平行线
程完成工作了，通知 JS 主线程执行回调函数了，回调函数也要等到 JS 主线程空闲时才能开始执行。以下就是这么一个例子。

function heavyCompute(n) {
    var count = 0,
        i, j;

    for (i = n; i > 0; --i) {
        for (j = n; j > 0; --j) {
            count += 1;
        }
    }
}

var t = new Date();

setTimeout(function () {
    console.log(new Date() - t);
}, 1000);

heavyCompute(50000);

-- Console ------------------------------
8520

可以看到，本来应该在 1 秒后被调用的回调函数因为 JS 主线程忙于运行其它代码，实际执行时间被大幅延迟。

代码设计模式

异步编程有很多特有的代码设计模式，为了实现同样的功能，使用同步方式和异步方式编写的代码会有很大差异。以下分别介绍一些常见的模式。

函数返回值

使用一个函数的输出作为另一个函数的输入是很常见的需求，在同步方式下一般按以下方式编写代码：

var output = fn1(fn2('input'));
// Do something.

而在异步方式下，由于函数执行结果不是通过返回值，而是通过回调函数传递，因此一般按以下方式编写代码：

fn2('input', function (output2) {
    fn1(output2, function (output1) {
        // Do something.
    });
});

可以看到，这种方式就是一个回调函数套一个回调函多，套得太多了很容易写出>形状的代码。

遍历数组

在遍历数组时，使用某个函数依次对数据成员做一些处理也是常见的需求。如果函数是同步执行的，一般就会写出以下代码：

var len = arr.length,
    i = 0;

for (; i < len; ++i) {
    arr[i] = sync(arr[i]);
}

// All array items have processed.

如果函数是异步执行的，以上代码就无法保证循环结束后所有数组成员都处理完毕了。如果数组成员必须一个接一个串行处理，则一般按照以下方式编
写异步代码：

(function next(i, len, callback) {
    if (i < len) {
        async(arr[i], function (value) {
            arr[i] = value;
            next(i + 1, len, callback);
        });
    } else {
        callback();
    }
}(0, arr.length, function () {
    // All array items have processed.
}));

可以看到，以上代码在异步函数执行一次并返回执行结果后才传入下一个数组成员并开始下一轮执行，直到所有数组成员处理完毕后，通过回调的方式
触发后续代码的执行。

如果数组成员可以并行处理，但后续代码仍然需要所有数组成员处理完毕后才能执行的话，则异步代码会调整成以下形式：

(function (i, len, count, callback) {
    for (; i < len; ++i) {
        (function (i) {
            async(arr[i], function (value) {
                arr[i] = value;
                if (++count === len) {
                    callback();
                }
            });
        }(i));
    }
}(0, arr.length, 0, function () {
    // All array items have processed.
}));

可以看到，与异步串行遍历的版本相比，以上代码并行处理所有数组成员，并通过计数器变量来判断什么时候所有数组成员都处理完毕了。

异常处理

JS 自身提供的异常捕获和处理机制——try..catch..，只能用于同步执行的代码。以下是一个例子。

function sync(fn) {
    return fn();
}

try {
    sync(null);
    // Do something.
} catch (err) {
    console.log('Error: %s', err.message);
}

-- Console ------------------------------
Error: object is not a function

可以看到，异常会沿着代码执行路径一直冒泡，直到遇到第一个 try 语句时被捕获住。但由于异步函数会打断代码执行路径，异步函数执行过程中以及
执行之后产生的异常冒泡到执行路径被打断的位置时，如果一直没有遇到 try 语句，就作为一个全局异常抛出。以下是一个例子。

function async(fn, callback) {
    // Code execution path breaks here.
    setTimeout(function ()　{
        callback(fn());
    }, 0);
}

try {
    async(null, function (data) {
        // Do something.
    });
} catch (err) {
    console.log('Error: %s', err.message);
}

-- Console ------------------------------
/home/user/test.js:4
        callback(fn());
                 ^
TypeError: object is not a function
    at null._onTimeout (/home/user/test.js:4:13)
    at Timer.listOnTimeout [as ontimeout] (timers.js:110:15)

因为代码执行路径被打断了，我们就需要在异常冒泡到断点之前用 try 语句把异常捕获住，并通过回调函数传递被捕获的异常。于是我们可以像下边这
样改造上边的例子。

function async(fn, callback) {
    // Code execution path breaks here.
    setTimeout(function ()　{
        try {
            callback(null, fn());
        } catch (err) {
            callback(err);
        }
    }, 0);
}

async(null, function (err, data) {
    if (err) {
        console.log('Error: %s', err.message);
    } else {
        // Do something.
    }
});

-- Console ------------------------------
Error: object is not a function

可以看到，异常再次被捕获住了。在 NodeJS 中，几乎所有异步 API 都按照以上方式设计，回调函数中第一个参数都是 err。因此我们在编写自己的异步函
数时，也可以按照这种方式来处理异常，与 NodeJS 的设计风格保持一致。

有了异常处理方式后，我们接着可以想一想一般我们是怎么写代码的。基本上，我们的代码都是做一些事情，然后调用一个函数，然后再做一些事情，
然后再调用一个函数，如此循环。如果我们写的是同步代码，只需要在代码入口点写一个 try 语句就能捕获所有冒泡上来的异常，示例如下。

function main() {
    // Do something.
    syncA();
    // Do something.
    syncB();
    // Do something.
    syncC();
}

try {
    main();
} catch (err) {
    // Deal with exception.
}

但是，如果我们写的是异步代码，就只有呵呵了。由于每次异步函数调用都会打断代码执行路径，只能通过回调函数来传递异常，于是我们就需要在每
个回调函数里判断是否有异常发生，于是只用三次异步函数调用，就会产生下边这种代码。

function main(callback) {
    // Do something.
    asyncA(function (err, data) {
        if (err) {
            callback(err);
        } else {
            // Do something
            asyncB(function (err, data) {
                if (err) {
                    callback(err);
                } else {
                    // Do something
                    asyncC(function (err, data) {
                        if (err) {
                            callback(err);
                        } else {
                            // Do something
                            callback(null);
                        }
                    });
                }
            });
        }
    });
}

main(function (err) {
    if (err) {
        // Deal with exception.
    }
});

可以看到，回调函数已经让代码变得复杂了，而异步方式下对异常的处理更加剧了代码的复杂度。如果 NodeJS 的最大卖点最后变成这个样子，那就没人
愿意用 NodeJS 了，因此接下来会介绍 NodeJS 提供的一些解决方案。

域（Domain）

    官方文档：http://nodejs.org/api/domain.html
   
NodeJS 提供了 domain 模块，可以简化异步代码的异常处理。在介绍该模块之前，我们需要首先理解“域”的概念。简单的讲，一个域就是一个 JS 运行环境
，在一个运行环境中，如果一个异常没有被捕获，将作为一个全局异常被抛出。NodeJS 通过 process 对象提供了捕获全局异常的方法，示例代码如下

process.on('uncaughtException', function (err) {
    console.log('Error: %s', err.message);
});

setTimeout(function (fn) {
    fn();
});

-- Console ------------------------------
Error: undefined is not a function

虽然全局异常有个地方可以捕获了，但是对于大多数异常，我们希望尽早捕获，并根据结果决定代码的执行路径。我们用以下 HTTP 服务器代码作为例子
：

function async(request, callback) {
    // Do something.
    asyncA(request, function (err, data) {
        if (err) {
            callback(err);
        } else {
            // Do something
            asyncB(request, function (err, data) {
                if (err) {
                    callback(err);
                } else {
                    // Do something
                    asyncC(request, function (err, data) {
                        if (err) {
                            callback(err);
                        } else {
                            // Do something
                            callback(null, data);
                        }
                    });
                }
            });
        }
    });
}

http.createServer(function (request, response) {
    async(request, function (err, data) {
        if (err) {
            response.writeHead(500);
            response.end();
        } else {
            response.writeHead(200);
            response.end(data);
        }
    });
});

以上代码将请求对象交给异步函数处理后，再根据处理结果返回响应。这里采用了使用回调函数传递异常的方案，因此 async 函数内部如果再多几个异
步函数调用的话，代码就变成上边这副鬼样子了。为了让代码好看点，我们可以在每处理一个请求时，使用 domain 模块创建一个子域（JS 子运行环境）
。在子域内运行的代码可以随意抛出异常，而这些异常可以通过子域对象的 error 事件统一捕获。于是以上代码可以做如下改造：

function async(request, callback) {
    // Do something.
    asyncA(request, function (data) {
        // Do something
        asyncB(request, function (data) {
            // Do something
            asyncC(request, function (data) {
                // Do something
                callback(data);
            });
        });
    });
}

http.createServer(function (request, response) {
    var d = domain.create();

    d.on('error', function () {
        response.writeHead(500);
        response.end();
    });

    d.run(function () {
        async(request, function (data) {
            response.writeHead(200);
            response.end(data);
        });
    });
});

可以看到，我们使用.create 方法创建了一个子域对象，并通过.run 方法进入需要在子域中运行的代码的入口点。而位于子域中的异步函数回调函数由
于不再需要捕获异常，代码一下子瘦身很多。

陷阱

无论是通过 process 对象的 uncaughtException 事件捕获到全局异常，还是通过子域对象的 error 事件捕获到了子域异常，在 NodeJS 官方文档里都强烈建
议处理完异常后立即重启程序，而不是让程序继续运行。按照官方文档的说法，发生异常后的程序处于一个不确定的运行状态，如果不立即退出的话，
程序可能会发生严重内存泄漏，也可能表现得很奇怪。

但这里需要澄清一些事实。JS 本身的 throw..try..catch 异常处理机制并不会导致内存泄漏，也不会让程序的执行结果出乎意料，但 NodeJS 并不是存粹
的 JS。NodeJS 里大量的 API 内部是用 C/C++实现的，因此 NodeJS 程序的运行过程中，代码执行路径穿梭于 JS 引擎内部和外部，而 JS 的异常抛出机制可能会
打断正常的代码执行流程，导致 C/C++部分的代码表现异常，进而导致内存泄漏等问题。

因此，使用 uncaughtException 或 domain 捕获异常，代码执行路径里涉及到了 C/C++部分的代码时，如果不能确定是否会导致内存泄漏等问题，最好在处
理完异常后重启程序比较妥当。而使用 try 语句捕获异常时一般捕获到的都是 JS 本身的异常，不用担心上诉问题。

小结

本章介绍了 JS 异步编程相关的知识，总结起来有以下几点：

  * 不掌握异步编程就不算学会 NodeJS。
   
  * 异步编程依托于回调来实现，而使用回调不一定就是异步编程。
   
  * 异步编程下的函数间数据传递、数组遍历和异常处理与同步编程有很大差别。
   
  * 使用 domain 模块简化异步代码的异常处理，并小心陷阱。
   
大示例

学习讲究的是学以致用和融会贯通。至此我们已经分别介绍了 NodeJS 的很多知识点，本章作为最后一章，将完整地介绍一个使用 NodeJS 开发 Web 服务器
的示例。

需求

我们要开发的是一个简单的静态文件合并服务器，该服务器需要支持类似以下格式的 JS 或 CSS 文件合并请求。

http://assets.example.com/foo/??bar.js,baz.js

在以上 URL 中，??是一个分隔符，之前是需要合并的多个文件的 URL 的公共部分，之后是使用,分隔的差异部分。因此服务器处理这个 URL 时，返回的是以
下两个文件按顺序合并后的内容。

/foo/bar.js
/foo/baz.js

另外，服务器也需要能支持类似以下格式的普通的 JS 或 CSS 文件请求。

http://assets.example.com/foo/bar.js

以上就是整个需求。

第一次迭代

快速迭代是一种不错的开发方式，因此我们在第一次迭代时先实现服务器的基本功能。

设计

简单分析了需求之后，我们大致会得到以下的设计方案。

           +---------+   +-----------+   +----------+
request -->|  parse  |-->|  combine  |-->|  output  |--> response
           +---------+   +-----------+   +----------+

也就是说，服务器会首先分析 URL，得到请求的文件的路径和类型（MIME）。然后，服务器会读取请求的文件，并按顺序合并文件内容。最后，服务器
返回响应，完成对一次请求的处理。

另外，服务器在读取文件时需要有个根目录，并且服务器监听的 HTTP 端口最好也不要写死在代码里，因此服务器需要是可配置的。

实现

根据以上设计，我们写出了第一版代码如下。

var fs = require('fs'),
    path = require('path'),
    http = require('http');

var MIME = {
    '.css': 'text/css',
    '.js': 'application/javascript'
};

function combineFiles(pathnames, callback) {
    var output = [];

    (function next(i, len) {
        if (i < len) {
            fs.readFile(pathnames[i], function (err, data) {
                if (err) {
                    callback(err);
                } else {
                    output.push(data);
                    next(i + 1, len);
                }
            });
        } else {
            callback(null, Buffer.concat(output));
        }
    }(0, pathnames.length));
}

function main(argv) {
    var config = JSON.parse(fs.readFileSync(argv[0], 'utf-8')),
        root = config.root || '.',
        port = config.port || 80;

    http.createServer(function (request, response) {
        var urlInfo = parseURL(root, request.url);

        combineFiles(urlInfo.pathnames, function (err, data) {
            if (err) {
                response.writeHead(404);
                response.end(err.message);
            } else {
                response.writeHead(200, {
                    'Content-Type': urlInfo.mime
                });
                response.end(data);
            }
        });
    }).listen(port);
}

function parseURL(root, url) {
    var base, pathnames, parts;

    if (url.indexOf('??') === -1) {
        url = url.replace('/', '/??');
    }

    parts = url.split('??');
    base = parts[0];
    pathnames = parts[1].split(',').map(function (value) {
        return path.join(root, base, value);
    });

    return {
        mime: MIME[path.extname(pathnames[0])] || 'text/plain',
        pathnames: pathnames
    };
}

main(process.argv.slice(2));

以上代码完整实现了服务器所需的功能，并且有以下几点值得注意：

 1. 使用命令行参数传递 JSON 配置文件路径，入口函数负责读取配置并创建服务器。
   
 2. 入口函数完整描述了程序的运行逻辑，其中解析 URL 和合并文件的具体实现封装在其它两个函数里。
   
 3. 解析 URL 时先将普通 URL 转换为了文件合并 URL，使得两种 URL 的处理方式可以一致。
   
 4. 合并文件时使用异步 API 读取文件，避免服务器因等待磁盘 IO 而发生阻塞。
   
我们可以把以上代码保存为 server.js，之后就可以通过 node server.js config.json 命令启动程序，于是我们的第一版静态文件合并服务器就顺利完
工了。

另外，以上代码存在一个不那么明显的逻辑缺陷。例如，使用以下 URL 请求服务器时会有惊喜。

    http://assets.example.com/foo/bar.js,foo/baz.js

经过分析之后我们会发现问题出在/被自动替换/??这个行为上，而这个问题我们可以到第二次迭代时再解决。

第二次迭代

在第一次迭代之后，我们已经有了一个可工作的版本，满足了功能需求。接下来我们需要从性能的角度出发，看看代码还有哪些改进余地。

设计

把 map 方法换成 for 循环或许会更快一些，但第一版代码最大的性能问题存在于从读取文件到输出响应的过程当中。我们以处理/??a.js,b.js,c.js 这个
请求为例，看看整个处理过程中耗时在哪儿。

 发送请求       等待服务端响应         接收响应
---------+----------------------+------------->
         --                                        解析请求
           ------                                  读取 a.js
                 ------                            读取 b.js
                       ------                      读取 c.js
                             --                    合并数据
                               --                  输出响应

可以看到，第一版代码依次把请求的文件读取到内存中之后，再合并数据和输出响应。这会导致以下两个问题：

 1. 当请求的文件比较多比较大时，串行读取文件会比较耗时，从而拉长了服务端响应等待时间。
   
 2. 由于每次响应输出的数据都需要先完整地缓存在内存里，当服务器请求并发数较大时，会有较大的内存开销。
   
对于第一个问题，很容易想到把读取文件的方式从串行改为并行。但是别这样做，因为对于机械磁盘而言，因为只有一个磁头，尝试并行读取文件只会
造成磁头频繁抖动，反而降低 IO 效率。而对于固态硬盘，虽然的确存在多个并行 IO 通道，但是对于服务器并行处理的多个请求而言，硬盘已经在做并行
IO 了，对单个请求采用并行 IO 无异于拆东墙补西墙。因此，正确的做法不是改用并行 IO，而是一边读取文件一边输出响应，把响应输出时机提前至读取
第一个文件的时刻。这样调整后，整个请求处理过程变成下边这样。

发送请求 等待服务端响应 接收响应
---------+----+------------------------------->
         --                                        解析请求
           --                                      检查文件是否存在
             --                                    输出响应头
               ------                              读取和输出 a.js
                     ------                        读取和输出 b.js
                           ------                  读取和输出 c.js

按上述方式解决第一个问题后，因为服务器不需要完整地缓存每个请求的输出数据了，第二个问题也迎刃而解。

实现

根据以上设计，第二版代码按以下方式调整了部分函数。

function main(argv) {
    var config = JSON.parse(fs.readFileSync(argv[0], 'utf-8')),
        root = config.root || '.',
        port = config.port || 80;

    http.createServer(function (request, response) {
        var urlInfo = parseURL(root, request.url);

        validateFiles(urlInfo.pathnames, function (err, pathnames) {
            if (err) {
                response.writeHead(404);
                response.end(err.message);
            } else {
                response.writeHead(200, {
                    'Content-Type': urlInfo.mime
                });
                outputFiles(pathnames, response);
            }
        });
    }).listen(port);
}

function outputFiles(pathnames, writer) {
    (function next(i, len) {
        if (i < len) {
            var reader = fs.createReadStream(pathnames[i]);

            reader.pipe(writer, { end: false });
            reader.on('end', function() {
                next(i + 1, len);
            });
        } else {
            writer.end();
        }
    }(0, pathnames.length));
}

function validateFiles(pathnames, callback) {
    (function next(i, len) {
        if (i < len) {
            fs.stat(pathnames[i], function (err, stats) {
                if (err) {
                    callback(err);
                } else if (!stats.isFile()) {
                    callback(new Error());
                } else {
                    next(i + 1, len);
                }
            });
        } else {
            callback(null, pathnames);
        }
    }(0, pathnames.length));
}

可以看到，第二版代码在检查了请求的所有文件是否有效之后，立即就输出了响应头，并接着一边按顺序读取文件一边输出响应内容。并且，在读取文
件时，第二版代码直接使用了只读数据流来简化代码。

第三次迭代

第二次迭代之后，服务器本身的功能和性能已经得到了初步满足。接下来我们需要从稳定性的角度重新审视一下代码，看看还需要做些什么。

设计

从工程角度上讲，没有绝对可靠的系统。即使第二次迭代的代码经过反复检查后能确保没有 bug，也很难说是否会因为 NodeJS 本身，或者是操作系统本
身，甚至是硬件本身导致我们的服务器程序在某一天挂掉。因此一般生产环境下的服务器程序都配有一个守护进程，在服务挂掉的时候立即重启服务。
一般守护进程的代码会远比服务进程的代码简单，从概率上可以保证守护进程更难挂掉。如果再做得严谨一些，甚至守护进程自身可以在自己挂掉时重
启自己，从而实现双保险。

因此在本次迭代时，我们先利用 NodeJS 的进程管理机制，将守护进程作为父进程，将服务器程序作为子进程，并让父进程监控子进程的运行状态，在其
异常退出时重启子进程。

实现

根据以上设计，我们编写了守护进程需要的代码。

var cp = require('child_process');

var worker;

function spawn(server, config) {
    worker = cp.spawn('node', [ server, config ]);
    worker.on('exit', function (code) {
        if (code !== 0) {
            spawn(server, config);
        }
    });
}

function main(argv) {
    spawn('server.js', argv[0]);
    process.on('SIGTERM', function () {
        worker.kill();
        process.exit(0);
    });
}

main(process.argv.slice(2));

此外，服务器代码本身的入口函数也要做以下调整。

function main(argv) {
    var config = JSON.parse(fs.readFileSync(argv[0], 'utf-8')),
        root = config.root || '.',
        port = config.port || 80,
        server;

    server = http.createServer(function (request, response) {
        ...
    }).listen(port);

    process.on('SIGTERM', function () {
        server.close(function () {
            process.exit(0);
        });
    });
}

我们可以把守护进程的代码保存为 daemon.js，之后我们可以通过 node daemon.js config.json 启动服务，而守护进程会进一步启动和监控服务器进程
。此外，为了能够正常终止服务，我们让守护进程在接收到 SIGTERM 信号时终止服务器进程。而在服务器进程这一端，同样在收到 SIGTERM 信号时先停掉
HTTP 服务再正常退出。至此，我们的服务器程序就靠谱很多了。

第四次迭代

在我们解决了服务器本身的功能、性能和可靠性的问题后，接着我们需要考虑一下代码部署的问题，以及服务器控制的问题。

设计

一般而言，程序在服务器上有一个固定的部署目录，每次程序有更新后，都重新发布到部署目录里。而一旦完成部署后，一般也可以通过固定的服务控
制脚本启动和停止服务。因此我们的服务器程序部署目录可以做如下设计。

- deploy/
    - bin/
        startws.sh
        killws.sh
    + conf/
        config.json
    + lib/
        daemon.js
        server.js

在以上目录结构中，我们分类存放了服务控制脚本、配置文件和服务器代码。

实现

按以上目录结构分别存放对应的文件之后，接下来我们看看控制脚本怎么写。首先是 start.sh。

#!/bin/sh
if [ ! -f "pid" ]
then
    node ../lib/daemon.js ../conf/config.json &
    echo $! > pid
fi

然后是 killws.sh。

#!/bin/sh
if [ -f "pid" ]
then
    kill $(tr -d '\r\n' < pid)
    rm pid
fi

于是这样我们就有了一个简单的代码部署目录和服务控制脚本，我们的服务器程序就可以上线工作了。

后续迭代

我们的服务器程序正式上线工作后，我们接下来或许会发现还有很多可以改进的点。比如服务器程序在合并 JS 文件时可以自动在 JS 文件之间插入一个;
来避免一些语法问题，比如服务器程序需要提供日志来统计访问量，比如服务器程序需要能充分利用多核 CPU，等等。而此时的你，在学习了这么久
NodeJS 之后，应该已经知道该怎么做了。

小结

本章将之前零散介绍的知识点串了起来，完整地演示了一个使用 NodeJS 开发程序的例子，至此我们的课程就全部结束了。以下是对新诞生的 NodeJSer 的
一些建议。

  * 要熟悉官方 API 文档。并不是说要熟悉到能记住每个 API 的名称和用法，而是要熟悉 NodeJS 提供了哪些功能，一旦需要时知道查询 API 文档的哪块地
    方。
   
  * 要先设计再实现。在开发一个程序前首先要有一个全局的设计，不一定要很周全，但要足够能写出一些代码。
   
  * 要实现后再设计。在写了一些代码，有了一些具体的东西后，一定会发现一些之前忽略掉的细节。这时再反过来改进之前的设计，为第二轮迭代做
    准备。
   
  * 要充分利用三方包。NodeJS 有一个庞大的生态圈，在写代码之前先看看有没有现成的三方包能节省不少时间。
   
  * 不要迷信三方包。任何事情做过头了就不好了，三方包也是一样。三方包是一个黑盒，每多使用一个三方包，就为程序增加了一份潜在风险。并且
    三方包很难恰好只提供程序需要的功能，每多使用一个三方包，就让程序更加臃肿一些。因此在决定使用某个三方包之前，最好三思而后行。
** 应用组成 
   1.引入 required 模块：我们可以使用 require 指令来载入 Node.js 模块。
   #+BEGIN_SRC js
   var http = require("http");
   #+END_SRC
   2.创建服务器：服务器可以监听客户端的请求，类似于 Apache、Nginx 等 HTTP 服务器。
  #+BEGIN_SRC js
  http.createServer(function (request, response) {

	// 发送 HTTP 头部 
	// HTTP 状态值: 200 : OK
	// 内容类型: text/plain
	response.writeHead(200, {'Content-Type': 'text/plain'});

	// 发送响应数据 "Hello World"
	response.end('Hello World\n');
}).listen(8888);

  #+END_SRC 
  
   3.接收请求与响应请求 服务器很容易创建，客户端可以使用浏览器或终端发送 HTTP 请
   求，服务器接收请求后返回响应数据。
#+BEGIN_SRC js
console.log('Server running at http://127.0.0.1:8888/');
#+END_SRC
** 事件驱动程序
Node.js 使用事件驱动模型，当 web server 接收到请求，就把它关闭然后进行处理，然后去
服务下一个 web 请求。当这个请求完成，它被放回处理队列，当到达队列开头，这个结果被
返回给用户。
#+BEGIN_SRC js
// 引入 events 模块
var events = require('events');
// 创建 eventEmitter 对象
var eventEmitter = new events.EventEmitter();

// 创建事件处理程序
var connectHandler = function connected() {
   console.log('连接成功。');
  
   // 触发 data_received 事件 
   eventEmitter.emit('data_received');
}

// 绑定 connection 事件处理程序
eventEmitter.on('connection', connectHandler);
 
// 使用匿名函数绑定 data_received 事件
eventEmitter.on('data_received', function(){
   console.log('数据接收成功。');
});

// 触发 connection 事件 
eventEmitter.emit('connection');

console.log("程序执行完毕。");
#+END_SRC
* node.js 学习笔记
** 输入   
   var readlineSync = require("readline-sync");
   // 等待输入
   var userName = readlineSync.question("May I have your name? ");
   console.log("Hi " + userName + "!");
   
   // 阴文输入
   var favFood = readlineSync.question("What is your favorite food? ", { hideEchoBack: true });
   console.log("Oh, " + userName + " loves " + favFood + "!");
*** 获取命令行参数(基本形式)
    console.log("hello ", process.argv[2]);
*** 获取命令行参数(option 形式: 如--help, -a)
    var argv = require("yargs").argv;
    console.log("hello ", argv.name);
 
  运行: ./hello --name=mike
  显示: hello mike
  单个字母用于短选项:
  console.log("hello ", argv.n);
  运行: ./hello -n mike
  显示: hello mike
  获取 option 之外(不带"--"或者"-"的)的命令行参数:

  console.log(argv._);
  更多选项配置:
  var argv = require("yargs")
      .option("n", { alias : "name", demand: true, default: "tom", describe: "your name", type: "string" })
      .argv;
  无参选项:
  var argv = require("yargs").boolean(["n"]).argv;
  帮助信息:
  2
 3
  4
  5
  6
  7
  var argv = require("yargs")
      .usage("Usage: hello [options]")
      .example("hello -n tom", "say hello to Tom")
      .help("h")
      .alias("h", "help")
      .epilog("copyright 2015")
      .argv;
  子命令(类似与 git commit):

  1
  2
  3
  4
  5
  6
  7
  8
  9
  var argv = require("yargs")
      .command("morning", "good morning", function (yargs) {
          console.log("Good Morning");
      })
      .command("evening", "good evening", function (yargs) {
          console.log("Good Evening");
      }).argv;
 
  console.log("hello ", argv.n);
  1.6 文件操作
  1.6.1 读取文本文件
  1
  2
  3
  4
  var text = fs.readFileSync(fileName, "utf8");
  text.split(/\r?\n/).forEach(function (line) {
      ...
  });
  1.6.2 写入文本文件
  1
  2
  3
  4
  fs.writeFileSync(fileName, str, 'utf8');
  var out = fs.createWriteStream(fileName, { encoding: "utf8" });
  out.write(str);
  out.end();
  1.6.3 判断文件是否存在
  1
  ret = fs.existsSync(path); // 返回 bool 类型, true 为存在.
  1.6.4 获取文件信息
  1
  ret = fs.statSync(path); // 返回 fs.Stats 的实例
  stats 类中的方法有:

  方法	描述
  stats.isFile()	如果是文件返回 true, 否则返回 false.
  stats.isDirectory()	如果是目录返回 true, 否则返回 false.
  stats.isBlockDevice()	如果是块设备返回 true, 否则返回 false.
  stats.isCharacterDevice()	如果是字符设备返回 true, 否则返回 false.
  stats.isSymbolicLink()	如果是软链接返回 true, 否则返回 false.
  stats.isFIFO()	如果是 FIFO, 返回 true, 否则返回 false. FIFO 是 UNIX 中的一种特殊类型的命令管道.
  stats.isSocket()	如果是 Socket 返回 true, 否则返回 false.
  1.7 管道
  1
  2
  3
  4
  5
  process.stdin.resume();
  process.stdin.setEncoding("utf8");
  process.stdin.on("data", function(data) {
      process.stdout.write(data);
  });
  运行: echo "foo" | ./hello
  显示: hello foo
  1.7.1 shell 命令间管道
  var proc = require('procstreams');
  proc('cat app.log').pipe('wc -l').data(function (stdout, stderr) {
      console.log(stdout);
  });
  1.7.2 重定向到文件
  1
  2
  cat('input.txt').to('output.txt');
  cat('input.txt').toEnd('output.txt');
  1.8 Linux 系统信号
  1
  2
  3
  4
  process.on("SIGINT", function () {
      console.log("User interrupted");
      process.exit(1);
  });
  1.9 进度条
  // width: 显示宽度, total: 总数据量, tick: 每次的数据量. 当所有 tick 的值加起来等于 total 则为 100%.
  var ProgressBar = require('progress');
 
  var cols = parseInt(sh.exec("echo $COLUMNS").stdout); // 获取终端列数
  var progressBar = new ProgressBar(':bar :percent ', { width: cols-5, total: 300, complete: "#" });
  var timer = setInterval(function () {
      progressBar.tick(10);
      if (progressBar.complete) {
          console.log('\ncomplete\n');
          clearInterval(timer);
      }
  }, 100);
  2 调用命令行程序
  2.1 通过 shelljs
  npm install shelljs
  shelljs 项目主页: https://github.com/shelljs/shelljs

  调用命令:

  1
  2
  var sh = require("shelljs");
  sh.echo("hello");
  调用命令的通用方法:

  1
  2
  ret = sh.exec("ls" + name, {silent:true}); // silent 表示不直接显示命令行输出, echo 除外.
  //结果分别在: ret.code, ret.stdout, ret.stderr 中.
  或者可以用 global 模式(目前已不建议, 因为会污染 global 环境):

  1
  2
  require("shelljs/global");
  echo("hello"); // global 模式下可以直接写 shell 命令.
  常用命令:

  1
  2
  3
  4
  5
  var ret = sh.find("../test/").filter(function(file) { return file.match(/\.js$/); }); // 返回数组
 
  sh.sed("-i", "PROGRAM_VERSION", "v0.1.3", "source.js");
  sh.sed(/.*DELETE_THIS_LINE.*\n/, "", "source.js");
  sh.sed(/(\w+)\s(\w+)/, "$2, $1", "file.txt");
  其他命令说明见: shelljs 项目主页

  模拟 xargs:

  1
  sh.ls("*.js").forEach(function(file) { sh.sed("-i", /.*REPLACE_LINE_WITH_MACRO.*\n/, sh.cat("macro.js"), file); });
  2.2 通过子进程
  var spawn = require("child_process").spawn;
  free = spawn("free", ["-m"]); 
 
  // 捕获标准输出并将其打印到控制台 
  free.stdout.on("data", function (data) { 
      console.log("standard output:\n" + data); 
  }); 
 
  // 捕获标准错误输出并将其打印到控制台 
  free.stderr.on("data", function (data) { 
      console.log("standard error output:\n" + data); 
  }); 
 
  // 注册子进程关闭事件 
  free.on("exit", function (code, signal) { 
      console.log("child process eixt ,exit:" + code); 
  });
  2.3 通过 exec
  require("child_process").exec; 
  var cmdStr = "curl http://www.weather.com.cn/data/sk/101010100.html";
  exec(cmdStr, function(err,stdout,stderr){
      if(err) {
          console.log("get weather api error:"+stderr);
      } else {
          /*
          这个 stdout 的内容就是上面我 curl 出来的这个东西:
          {"weatherinfo":{"city":"北京","cityid":"101010100","temp":"3",
          "WD":"西北风","WS":"3 级","SD":"23%","WSE":"3","time":"21:20",
          "isRadar":"1","Radar":"JC_RADAR_AZ9010_JB","njd":"暂无实况","qy":"1019"}}
          */
          var data = JSON.parse(stdout);
          console.log(data);
      }
  });
  2.4 调用 shell 脚本
  调用传参数的 shell 脚本(child_process.execFile())

  var callfile = require("child_process").execFile;
  var username = "test";
  callfile("a.sh", ["-U", username], null, function (err, stdout, stderr) {
      ...
  });
  2.5 同步调用子进程
  var execSync = require('child_process').execSync;
 
  try {
      var result = execSync("git log", { encoding: "utf8" });
      process.stdout.write(result);
  } catch(e) {
      console.log(e.status); // 命令返回值
      console.log(e.stderr); // err 信息
  }
  3 log 系统
  3.1 (console-log-level)可以控制打印级别的简单 log 模块:
  与 console.log 类似, 只是添加了打印级别的控制. 适合简单的单一文件脚本的简单 log 需求.

  npm install console-log-level
  用法:

  var logger = require('console-log-level')({ level: 'info' })
 
  logger.debug('b') // will not do anything 
  logger.info('c')  // will output 'c\n' on STDOUT 
  logger.warn('d')  // will output 'd\n' on STDERR 
  logger.error('e') // will output 'e\n' on STDERR 
* 代码的组织和部署
** 模块
   NODE_PATH=/home/user/lib:/home/lib
   当使用 require(‘foo/bar’)的方式加载模块时，则 NodeJS 依次尝试以下路径。
*** 包（package）
当模块的文件名是 index.js，加载模块时可以使用模块所在目录的路径代替模块文件路径，
因此接着上例，以下两条语句等价。

var cat = require('/home/user/lib/cat');
var cat = require('/home/user/lib/cat/index');
*** package.json
    如果想自定义入口模块的文件名和存放位置，就需要在包目录下包含一个 package.json 文件，并在其中指定入口模块的路径。上例中的 cat 模块可以重构如下。

其中 package.json 内容如下。
{
    "name": "cat",
    "main": "./lib/main.js"
}
*** 工程目录
了解了以上知识后，现在我们可以来完整地规划一个工程目录了。以编写一个命令行程序为例，一般我们会同时提供命令行模式和 API 模式两种使用方式，并且我们会借助三方包来编写代码。除了代码外，一个完整的程序也应该有自己的文档和测试用例。因此，一个标准的工程目录都看起来像下边这样。

- /home/user/workspace/node-echo/   # 工程目录
    - bin/                          # 存放命令行相关代码
        node-echo
    + doc/                          # 存放文档
    - lib/                          # 存放 API 相关代码
        echo.js
    - node_modules/                 # 存放三方包
        + argv/
    + tests/                        # 存放测试用例
    package.json                    # 元数据文件
    README.md                       # 说明文件
其中部分文件内容如下：

/* bin/node-echo */
var argv = require('argv'),
    echo = require('../lib/echo');
console.log(echo(argv.join(' ')));
 
/* lib/echo.js */
module.exports = function (message) {
    return message;
};
 
/* package.json */
{
    "name": "node-echo",
    "main": "./lib/echo.js"
}
以上例子中分类存放了不同类型的文件，并通过 node_moudles 目录直接使用三方包名加载模块。此外，定义了 package.json 之后，node-echo 目录也可被当作一个包来使用。

* 文件操作
NodeJS 提供了基本的文件操作 API，但是像文件拷贝这种高级功能就没有提供，因此我们先
拿文件拷贝程序练手。与 copy 命令类似，我们的程序需要能接受源文件路径与目标文件路径
两个参数。

小文件拷贝
我们使用 NodeJS 内置的 fs 模块简单实现这个程序如下。

var fs = require('fs');
function copy(src, dst) {
    fs.writeFileSync(dst, fs.readFileSync(src));
}
 
function main(argv) {
    copy(argv[0], argv[1]);
}
 
main(process.argv.slice(2));

以上程序使用 fs.readFileSync 从源路径读取文件内容，并使用 fs.writeFileSync 将文件内
容写入目标路径。

豆知识：process 是一个全局变量，可通过 process.argv 获得命令行参数。由于 argv[0]固
定等于 NodeJS 执行程序的绝对路径，argv[1]固定等于主模块的绝对路径，因此第一个命令
行参数从 argv[2]这个位置开始。

大文件拷贝
上边的程序拷贝一些小文件没啥问题，但这种一次性把所有文件内容都读取到内存中后再一次性写入磁盘的方式不适合拷贝大文件，内存会爆仓。对于大文件，我们只能读一点写一点，直到完成拷贝。因此上边的程序需要改造如下。

var fs = require('fs');
 
function copy(src, dst) {
    fs.createReadStream(src).pipe(fs.createWriteStream(dst));
}
 
function main(argv) {
    copy(argv[0], argv[1]);
}
 
main(process.argv.slice(2));
以上程序使用 fs.createReadStream 创建了一个源文件的只读数据流，并使用 fs.createWriteStream 创建了一个目标文件的只写数据流，并且用 pipe 方法把两个数据流连接了起来。连接起来后发生的事情，说得抽象点的话，水顺着水管从一个桶流到了另一个桶。

API 走马观花
我们先大致看看 NodeJS 提供了哪些和文件操作有关的 API。这里并不逐一介绍每个 API 的使用方法，官方文档已经做得很好了。

Buffer（数据块）
官方文档：http://nodejs.org/api/buffer.html

JS 语言自身只有字符串数据类型，没有二进制数据类型，因此 NodeJS 提供了一个与 String 对等的全局构造函数 Buffer 来提供对二进制数据的操作。除了可以读取文件得到 Buffer 的实例外，还能够直接构造，例如：

var bin = new Buffer([ 0x68, 0x65, 0x6c, 0x6c, 0x6f ]);
Buffer 与字符串类似，除了可以用.length 属性得到字节长度外，还可以用[index]方式读取指定位置的字节，例如：

bin[0]; // => 0x68;
Buffer 与字符串能够互相转化，例如可以使用指定编码将二进制数据转化为字符串：

var str = bin.toString('utf-8'); // => "hello"
或者反过来，将字符串转换为指定编码下的二进制数据：

var bin = new Buffer('hello', 'utf-8'); // => <buffer 68="" 65="" 6c="" 6f="">
</buffer>
Buffer 与字符串有一个重要区别。字符串是只读的，并且对字符串的任何修改得到的都是一个新字符串，原字符串保持不变。至于 Buffer，更像是可以做指针操作的 C 语言数组。例如，可以用[index]方式直接修改某个位置的字节。

bin[0] = 0x48;
而.slice 方法也不是返回一个新的 Buffer，而更像是返回了指向原 Buffer 中间的某个位置的指针，如下所示。

[ 0x68, 0x65, 0x6c, 0x6c, 0x6f ]
    ^           ^
    |           |
   bin     bin.slice(2)
因此对.slice 方法返回的 Buffer 的修改会作用于原 Buffer，例如：

var bin = new Buffer([ 0x68, 0x65, 0x6c, 0x6c, 0x6f ]);
var sub = bin.slice(2);
 
sub[0] = 0x65;
console.log(bin); // => <buffer 68="" 65="" 6c="" 6f="">
</buffer>
也因此，如果想要拷贝一份 Buffer，得首先创建一个新的 Buffer，并通过.copy 方法把原 Buffer 中的数据复制过去。这个类似于申请一块新的内存，并把已有内存中的数据复制过去。以下是一个例子。

var bin = new Buffer([ 0x68, 0x65, 0x6c, 0x6c, 0x6f ]);
var dup = new Buffer(bin.length);
 
bin.copy(dup);
dup[0] = 0x48;
console.log(bin); // => <buffer 68="" 65="" 6c="" 6f="">
console.log(dup); // => <buffer 48="" 65="" 6c="" 6f="">
</buffer></buffer>
总之，Buffer 将 JS 的数据处理能力从字符串扩展到了任意二进制数据。

Stream（数据流）
官方文档：http://nodejs.org/api/stream.html

当内存中无法一次装下需要处理的数据时，或者一边读取一边处理更加高效时，我们就需要用到数据流。NodeJS 中通过各种 Stream 来提供对数据流的操作。

以上边的大文件拷贝程序为例，我们可以为数据来源创建一个只读数据流，示例如下：

var rs = fs.createReadStream(pathname);
 
rs.on('data', function (chunk) {
    doSomething(chunk);
});
 
rs.on('end', function () {
    cleanUp();
});
豆知识：Stream 基于事件机制工作，所有 Stream 的实例都继承于 NodeJS 提供的 EventEmitter。

上边的代码中 data 事件会源源不断地被触发，不管 doSomething 函数是否处理得过来。代码可以继续做如下改造，以解决这个问题。

var rs = fs.createReadStream(src);
 
rs.on('data', function (chunk) {
    rs.pause();
    doSomething(chunk, function () {
        rs.resume();
    });
});
 
rs.on('end', function () {
    cleanUp();
});
以上代码给 doSomething 函数加上了回调，因此我们可以在处理数据前暂停数据读取，并在处理数据后继续读取数据。

此外，我们也可以为数据目标创建一个只写数据流，示例如下：

var rs = fs.createReadStream(src);
var ws = fs.createWriteStream(dst);
 
rs.on('data', function (chunk) {
    ws.write(chunk);
});
 
rs.on('end', function () {
    ws.end();
});
我们把 doSomething 换成了往只写数据流里写入数据后，以上代码看起来就像是一个文件拷贝程序了。但是以上代码存在上边提到的问题，如果写入速度跟不上读取速度的话，只写数据流内部的缓存会爆仓。我们可以根据.write 方法的返回值来判断传入的数据是写入目标了，还是临时放在了缓存了，并根据 drain 事件来判断什么时候只写数据流已经将缓存中的数据写入目标，可以传入下一个待写数据了。因此代码可以改造如下：

var rs = fs.createReadStream(src);
var ws = fs.createWriteStream(dst);
 
rs.on('data', function (chunk) {
    if (ws.write(chunk) === false) {
        rs.pause();
    }
});
 
rs.on('end', function () {
    ws.end();
});
 
ws.on('drain', function () {
    rs.resume();
});
以上代码实现了数据从只读数据流到只写数据流的搬运，并包括了防爆仓控制。因为这种使用场景很多，例如上边的大文件拷贝程序，NodeJS 直接提供了.pipe 方法来做这件事情，其内部实现方式与上边的代码类似。

File System（文件系统）
官方文档：http://nodejs.org/api/fs.html

NodeJS 通过 fs 内置模块提供对文件的操作。fs 模块提供的 API 基本上可以分为以下三类：

文件属性读写。
其中常用的有 fs.stat、fs.chmod、fs.chown 等等。

文件内容读写。
其中常用的有 fs.readFile、fs.readdir、fs.writeFile、fs.mkdir 等等。

底层文件操作。
其中常用的有 fs.open、fs.read、fs.write、fs.close 等等。

NodeJS 最精华的异步 IO 模型在 fs 模块里有着充分的体现，例如上边提到的这些 API 都通过回调函数传递结果。以 fs.readFile 为例：

fs.readFile(pathname, function (err, data) {
    if (err) {
        // Deal with error.
    } else {
        // Deal with data.
    }
});
如上边代码所示，基本上所有 fs 模块 API 的回调参数都有两个。第一个参数在有错误发生时等于异常对象，第二个参数始终用于返回 API 方法执行结果。

此外，fs 模块的所有异步 API 都有对应的同步版本，用于无法使用异步操作时，或者同步操作更方便时的情况。同步 API 除了方法名的末尾多了一个 Sync 之外，异常对象与执行结果的传递方式也有相应变化。同样以 fs.readFileSync 为例：

try {
    var data = fs.readFileSync(pathname);
    // Deal with data.
} catch (err) {
    // Deal with error.
}
fs 模块提供的 API 很多，这里不一一介绍，需要时请自行查阅官方文档。

Path（路径）
官方文档：http://nodejs.org/api/path.html

操作文件时难免不与文件路径打交道。NodeJS 提供了 path 内置模块来简化路径相关操作，并提升代码可读性。以下分别介绍几个常用的 API。

path.normalize
将传入的路径转换为标准路径，具体讲的话，除了解析路径中的.与..外，还能去掉多余的斜杠。如果有程序需要使用路径作为某些数据的索引，但又允许用户随意输入路径时，就需要使用该方法保证路径的唯一性。以下是一个例子：

var cache = {};
 
function store(key, value) {
    cache[path.normalize(key)] = value;
}
 
store('foo/bar', 1);
store('foo//baz//../bar', 2);
console.log(cache);  // => { "foo/bar": 2 }
坑出没注意： 标准化之后的路径里的斜杠在 Windows 系统下是\，而在 Linux 系统下是/。如果想保证任何系统下都使用/作为路径分隔符的话，需要用.replace(/\\/g, ‘/’)再替换一下标准路径。

path.join
将传入的多个路径拼接为标准路径。该方法可避免手工拼接路径字符串的繁琐，并且能在不同系统下正确使用相应的路径分隔符。以下是一个例子：

path.join('foo/', 'baz/', '../bar'); // => "foo/bar"
path.extname
当我们需要根据不同文件扩展名做不同操作时，该方法就显得很好用。以下是一个例子：

path.extname('foo/bar.js'); // => ".js"
path 模块提供的其余方法也不多，稍微看一下官方文档就能全部掌握。

遍历目录
遍历目录是操作文件时的一个常见需求。比如写一个程序，需要找到并处理指定目录下的所有 JS 文件时，就需要遍历整个目录。

递归算法
遍历目录时一般使用递归算法，否则就难以编写出简洁的代码。递归算法与数学归纳法类似，通过不断缩小问题的规模来解决问题。以下示例说明了这种方法。

function factorial(n) {
    if (n === 1) {
        return 1;
    } else {
        return n * factorial(n - 1);
    }
}
上边的函数用于计算 N 的阶乘（N!）。可以看到，当 N 大于 1 时，问题简化为计算 N 乘以 N-1 的阶乘。当 N 等于 1 时，问题达到最小规模，不需要再简化，因此直接返回 1。

陷阱： 使用递归算法编写的代码虽然简洁，但由于每递归一次就产生一次函数调用，在需要优先考虑性能时，需要把递归算法转换为循环算法，以减少函数调用次数。

遍历算法
目录是一个树状结构，在遍历时一般使用深度优先+先序遍历算法。深度优先，意味着到达一个节点后，首先接着遍历子节点而不是邻居节点。先序遍历，意味着首次到达了某节点就算遍历完成，而不是最后一次返回某节点才算数。因此使用这种遍历方式时，下边这棵树的遍历顺序是 A > B > D > E > C > F。

    A
   / \
  B   C
 / \   \
D   E   F
同步遍历
了解了必要的算法后，我们可以简单地实现以下目录遍历函数。

function travel(dir, callback) {
    fs.readdirSync(dir).forEach(function (file) {
        var pathname = path.join(dir, file);
 
        if (fs.statSync(pathname).isDirectory()) {
            travel(pathname, callback);
        } else {
            callback(pathname);
        }
    });
}
可以看到，该函数以某个目录作为遍历的起点。遇到一个子目录时，就先接着遍历子目录。遇到一个文件时，就把文件的绝对路径传给回调函数。回调函数拿到文件路径后，就可以做各种判断和处理。因此假设有以下目录：

- /home/user/
    - foo/
        x.js
    - bar/
        y.js
    z.css
使用以下代码遍历该目录时，得到的输入如下。

travel('/home/user', function (pathname) {
    console.log(pathname);
});
 
------------------------
/home/user/foo/x.js
/home/user/bar/y.js
/home/user/z.css
异步遍历
如果读取目录或读取文件状态时使用的是异步 API，目录遍历函数实现起来会有些复杂，但原理完全相同。travel 函数的异步版本如下。

function travel(dir, callback, finish) {
    fs.readdir(dir, function (err, files) {
        (function next(i) {
            if (i < files.length) {
                var pathname = path.join(dir, files[i]);
 
                fs.stat(pathname, function (err, stats) {
                    if (stats.isDirectory()) {
                        travel(pathname, callback, function () {
                            next(i + 1);
                        });
                    } else {
                        callback(pathname, function () {
                            next(i + 1);
                        });
                    }
                });
            } else {
                finish && finish();
            }
        }(0));
    });
}
这里不详细介绍异步遍历函数的编写技巧，在后续章节中会详细介绍这个。总之我们可以看到异步编程还是蛮复杂的。

文本编码
使用 NodeJS 编写前端工具时，操作得最多的是文本文件，因此也就涉及到了文件编码的处理问题。我们常用的文本编码有 UTF8 和 GBK 两种，并且 UTF8 文件还可能带有 BOM。在读取不同编码的文本文件时，需要将文件内容转换为 JS 使用的 UTF8 编码字符串后才能正常处理。

BOM 的移除
BOM 用于标记一个文本文件使用 Unicode 编码，其本身是一个 Unicode 字符（"\uFEFF"），位于文本文件头部。在不同的 Unicode 编码下，BOM 字符对应的二进制字节如下：

    Bytes      Encoding
----------------------------
    FE FF       UTF16BE
    FF FE       UTF16LE
    EF BB BF    UTF8
因此，我们可以根据文本文件头几个字节等于啥来判断文件是否包含 BOM，以及使用哪种 Unicode 编码。但是，BOM 字符虽然起到了标记文件编码的作用，其本身却不属于文件内容的一部分，如果读取文本文件时不去掉 BOM，在某些使用场景下就会有问题。例如我们把几个 JS 文件合并成一个文件后，如果文件中间含有 BOM 字符，就会导致浏览器 JS 语法错误。因此，使用 NodeJS 读取文本文件时，一般需要去掉 BOM。例如，以下代码实现了识别和去除 UTF8 BOM 的功能。

function readText(pathname) {
    var bin = fs.readFileSync(pathname);
 
    if (bin[0] === 0xEF && bin[1] === 0xBB && bin[2] === 0xBF) {
        bin = bin.slice(3);
    }
 
    return bin.toString('utf-8');
}
GBK 转 UTF8
NodeJS 支持在读取文本文件时，或者在 Buffer 转换为字符串时指定文本编码，但遗憾的是，GBK 编码不在 NodeJS 自身支持范围内。因此，一般我们借助 iconv-lite 这个三方包来转换编码。使用 NPM 下载该包后，我们可以按下边方式编写一个读取 GBK 文本文件的函数。

var iconv = require('iconv-lite');
 
function readGBKText(pathname) {
    var bin = fs.readFileSync(pathname);
 
    return iconv.decode(bin, 'gbk');
}
单字节编码
有时候，我们无法预知需要读取的文件采用哪种编码，因此也就无法指定正确的编码。比如我们要处理的某些 CSS 文件中，有的用 GBK 编码，有的用 UTF8 编码。虽然可以一定程度可以根据文件的字节内容猜测出文本编码，但这里要介绍的是有些局限，但是要简单得多的一种技术。

首先我们知道，如果一个文本文件只包含英文字符，比如 Hello World，那无论用 GBK 编码或是 UTF8 编码读取这个文件都是没问题的。这是因为在这些编码下，ASCII0~128 范围内字符都使用相同的单字节编码。

反过来讲，即使一个文本文件中有中文等字符，如果我们需要处理的字符仅在 ASCII0~128 范围内，比如除了注释和字符串以外的 JS 代码，我们就可以统一使用单字节编码来读取文件，不用关心文件的实际编码是 GBK 还是 UTF8。以下示例说明了这种方法。

1. GBK 编码源文件内容：
    var foo = '中文';
2. 对应字节：
    76 61 72 20 66 6F 6F 20 3D 20 27 D6 D0 CE C4 27 3B
3. 使用单字节编码读取后得到的内容：
    var foo = '{乱码}{乱码}{乱码}{乱码}';
4. 替换内容：
    var bar = '{乱码}{乱码}{乱码}{乱码}';
5. 使用单字节编码保存后对应字节：
    76 61 72 20 62 61 72 20 3D 20 27 D6 D0 CE C4 27 3B
6. 使用 GBK 编码读取后得到内容：
    var bar = '中文';
这里的诀窍在于，不管大于 0xEF 的单个字节在单字节编码下被解析成什么乱码字符，使用同样的单字节编码保存这些乱码字符时，背后对应的字节保持不变。

NodeJS 中自带了一种 binary 编码可以用来实现这个方法，因此在下例中，我们使用这种编码来演示上例对应的代码该怎么写。

function replace(pathname) {
    var str = fs.readFileSync(pathname, 'binary');
    str = str.replace('foo', 'bar');
    fs.writeFileSync(pathname, str, 'binary');
}
小结
本章介绍了使用 NodeJS 操作文件时需要的 API 以及一些技巧，总结起来有以下几点：

学好文件操作，编写各种程序都不怕。如果不是很在意性能，fs 模块的同步 API 能让生活更加美好。需要对文件读写做到字节级别的精细控制时，请使用 fs 模块的文件底层操作 API。不要使用拼接字符串的方式来处理路径，使用 path 模块。掌握好目录遍历和文件编码处理技巧，很实用。
1 开门红
1.1 小文件拷贝
1.2 大文件拷贝
2API 走马观花
2.1Buffer（数据块）
2.2Stream（数据流）
2.3File System（文件系统）
2.4Path（路径）
3 遍历目录
3.1 递归算法
3.2 遍历算法
3.3 同步遍历
3.4 异步遍历
4 文本编码
4.1BOM 的移除
4.2GBK 转 UTF8
4.3 单字节编码
5 小结
关于我们 联系我们 广告服务 免责声明
© 2012-2016 jqhtml.com · 湘 ICP 备 16001111 号-1 · 托管于 阿里云 & 又拍云
* 网络操作
不了解网络编程的程序员不是好前端，而 NodeJS 恰好提供了一扇了解网络编程的窗口。通过 NodeJS，除了可以编写一些服务端程序来协助前端开发和测试外，还能够学习一些 HTTP 协议与 Socket 协议的相关知识，这些知识在优化前端性能和排查前端故障时说不定能派上用场。本章将介绍与之相关的 NodeJS 内置模块。

开门红
NodeJS 本来的用途是编写高性能 Web 服务器。我们首先在这里重复一下官方文档里的例子，使用 NodeJS 内置的 http 模块简单实现一个 HTTP 服务器。

var http = require('http');
 
http.createServer(function (request, response) {
    response.writeHead(200, { 'Content-Type': 'text-plain' });
    response.end('Hello World\n');
}).listen(8124);
以上程序创建了一个 HTTP 服务器并监听 8124 端口，打开浏览器访问该端口 http://127.0.0.1:8124/就能够看到效果。

豆知识： 在 Linux 系统下，监听 1024 以下端口需要 root 权限。因此，如果想监听 80 或 443 端口的话，需要使用 sudo 命令启动程序。

API 走马观花
我们先大致看看 NodeJS 提供了哪些和网络操作有关的 API。这里并不逐一介绍每个 API 的使用方法，官方文档已经做得很好了。

HTTP
官方文档：http://nodejs.org/api/http.html

‘http’模块提供两种使用方式：

作为服务端使用时，创建一个 HTTP 服务器，监听 HTTP 客户端请求并返回响应。作为客户端使用时，发起一个 HTTP 客户端请求，获取服务端响应。
首先我们来看看服务端模式下如何工作。如开门红中的例子所示，首先需要使用.createServer 方法创建一个服务器，然后调用.listen 方法监听端口。之后，每当来了一个客户端请求，创建服务器时传入的回调函数就被调用一次。可以看出，这是一种事件机制。

HTTP 请求本质上是一个数据流，由请求头（headers）和请求体（body）组成。例如以下是一个完整的 HTTP 请求数据内容。

POST / HTTP/1.1
User-Agent: curl/7.26.0
Host: localhost
Accept: */*
Content-Length: 11
Content-Type: application/x-www-form-urlencoded
 
Hello World
可以看到，空行之上是请求头，之下是请求体。HTTP 请求在发送给服务器时，可以认为是按照从头到尾的顺序一个字节一个字节地以数据流方式发送的。而 http 模块创建的 HTTP 服务器在接收到完整的请求头后，就会调用回调函数。在回调函数中，除了可以使用 request 对象访问请求头数据外，还能把 request 对象当作一个只读数据流来访问请求体数据。以下是一个例子。

http.createServer(function (request, response) {
    var body = [];
 
    console.log(request.method);
    console.log(request.headers);
 
    request.on('data', function (chunk) {
        body.push(chunk);
    });
 
    request.on('end', function () {
        body = Buffer.concat(body);
        console.log(body.toString());
    });
}).listen(80);
 
------------------------------------
POST
{ 'user-agent': 'curl/7.26.0',
  host: 'localhost',
  accept: '*/*',
  'content-length': '11',
  'content-type': 'application/x-www-form-urlencoded' }
Hello World
HTTP 响应本质上也是一个数据流，同样由响应头（headers）和响应体（body）组成。例如以下是一个完整的 HTTP 请求数据内容。

HTTP/1.1 200 OK
Content-Type: text/plain
Content-Length: 11
Date: Tue, 05 Nov 2013 05:31:38 GMT
Connection: keep-alive
 
Hello World
在回调函数中，除了可以使用 response 对象来写入响应头数据外，还能把 response 对象当作一个只写数据流来写入响应体数据。例如在以下例子中，服务端原样将客户端请求的请求体数据返回给客户端。

http.createServer(function (request, response) {
    response.writeHead(200, { 'Content-Type': 'text/plain' });
 
    request.on('data', function (chunk) {
        response.write(chunk);
    });
 
    request.on('end', function () {
        response.end();
    });
}).listen(80);
接下来我们看看客户端模式下如何工作。为了发起一个客户端 HTTP 请求，我们需要指定目标服务器的位置并发送请求头和请求体，以下示例演示了具体做法。

var options = {
        hostname: 'www.example.com',
        port: 80,
        path: '/upload',
        method: 'POST',
        headers: {
            'Content-Type': 'application/x-www-form-urlencoded'
        }
    };
 
var request = http.request(options, function (response) {});
 
request.write('Hello World');
request.end();
可以看到，.request 方法创建了一个客户端，并指定请求目标和请求头数据。之后，就可以把 request 对象当作一个只写数据流来写入请求体数据和结束请求。另外，由于 HTTP 请求中 GET 请求是最常见的一种，并且不需要请求体，因此 http 模块也提供了以下便捷 API。

http.get('http://www.example.com/', function (response) {});
当客户端发送请求并接收到完整的服务端响应头时，就会调用回调函数。在回调函数中，除了可以使用 response 对象访问响应头数据外，还能把 response 对象当作一个只读数据流来访问响应体数据。以下是一个例子。

http.get('http://www.example.com/', function (response) {
    var body = [];
 
    console.log(response.statusCode);
    console.log(response.headers);
 
    response.on('data', function (chunk) {
        body.push(chunk);
    });
 
    response.on('end', function () {
        body = Buffer.concat(body);
        console.log(body.toString());
    });
});
 
------------------------------------
200
{ 'content-type': 'text/html',
  server: 'Apache',
  'content-length': '801',
  date: 'Tue, 05 Nov 2013 06:08:41 GMT',
  connection: 'keep-alive' }
 
...
HTTPS
官方文档： <a href="http://nodejs.org/api/https.html" target="_blank">http://nodejs.org/api/https.html</a>
https 模块与 http 模块极为类似，区别在于 https 模块需要额外处理 SSL 证书。

在服务端模式下，创建一个 HTTPS 服务器的示例如下。

var options = {
        key: fs.readFileSync('./ssl/default.key'),
        cert: fs.readFileSync('./ssl/default.cer')
    };
 
var server = https.createServer(options, function (request, response) {
        // ...
    });
可以看到，与创建 HTTP 服务器相比，多了一个 options 对象，通过 key 和 cert 字段指定了 HTTPS 服务器使用的私钥和公钥。

另外，NodeJS 支持 SNI 技术，可以根据 HTTPS 客户端请求使用的域名动态使用不同的证书，因此同一个 HTTPS 服务器可以使用多个域名提供服务。接着上例，可以使用以下方法为 HTTPS 服务器添加多组证书。

server.addContext('foo.com', {
    key: fs.readFileSync('./ssl/foo.com.key'),
    cert: fs.readFileSync('./ssl/foo.com.cer')
});
 
server.addContext('bar.com', {
    key: fs.readFileSync('./ssl/bar.com.key'),
    cert: fs.readFileSync('./ssl/bar.com.cer')
});
在客户端模式下，发起一个 HTTPS 客户端请求与 http 模块几乎相同，示例如下。

var options = {
        hostname: 'www.example.com',
        port: 443,
        path: '/',
        method: 'GET'
    };
 
var request = https.request(options, function (response) {});
 
request.end();
但如果目标服务器使用的 SSL 证书是自制的，不是从颁发机构购买的，默认情况下 https 模块会拒绝连接，提示说有证书安全问题。在 options 里加入 rejectUnauthorized: false 字段可以禁用对证书有效性的检查，从而允许 https 模块请求开发环境下使用自制证书的 HTTPS 服务器。

URL
官方文档：http://nodejs.org/api/url.html

处理 HTTP 请求时 url 模块使用率超高，因为该模块允许解析 URL、生成 URL，以及拼接 URL。首先我们来看看一个完整的 URL 的各组成部分。

                           href
 -----------------------------------------------------------------
                            host              path
                      --------------- ----------------------------
 http: // user:pass @ host.com : 8080 /p/a/t/h ?query=string #hash
 -----    ---------   --------   ---- -------- ------------- -----
protocol     auth     hostname   port pathname     search     hash
                                                ------------
                                                   query
我们可以使用.parse 方法来将一个 URL 字符串转换为 URL 对象，示例如下。

url.parse('http://user:pass@host.com:8080/p/a/t/h?query=string#hash');
/* =>
{ protocol: 'http:',
  auth: 'user:pass',
  host: 'host.com:8080',
  port: '8080',
  hostname: 'host.com',
  hash: '#hash',
  search: '?query=string',
  query: 'query=string',
  pathname: '/p/a/t/h',
  path: '/p/a/t/h?query=string',
  href: 'http://user:pass@host.com:8080/p/a/t/h?query=string#hash' }
*/
传给.parse 方法的不一定要是一个完整的 URL，例如在 HTTP 服务器回调函数中，request.url 不包含协议头和域名，但同样可以用.parse 方法解析。

http.createServer(function (request, response) {
    var tmp = request.url; // => "/foo/bar?a=b"
    url.parse(tmp);
    /* =>
    { protocol: null,
      slashes: null,
      auth: null,
      host: null,
      port: null,
      hostname: null,
      hash: null,
      search: '?a=b',
      query: 'a=b',
      pathname: '/foo/bar',
      path: '/foo/bar?a=b',
      href: '/foo/bar?a=b' }
    */
}).listen(80);
.parse 方法还支持第二个和第三个布尔类型可选参数。第二个参数等于 true 时，该方法返回的 URL 对象中，query 字段不再是一个字符串，而是一个经过 querystring 模块转换后的参数对象。第三个参数等于 true 时，该方法可以正确解析不带协议头的 URL，例如//www.example.com/foo/bar。

反过来，format 方法允许将一个 URL 对象转换为 URL 字符串，示例如下。

url.format({
    protocol: 'http:',
    host: 'www.example.com',
    pathname: '/p/a/t/h',
    search: 'query=string'
});
/* =>
'http://www.example.com/p/a/t/h?query=string'
*/
另外，.resolve 方法可以用于拼接 URL，示例如下。

url.resolve('http://www.example.com/foo/bar', '../baz');
/* =>
http://www.example.com/baz
*/
Query String
官方文档：http://nodejs.org/api/querystring.html

querystring 模块用于实现 URL 参数字符串与参数对象的互相转换，示例如下。

querystring.parse('foo=bar&baz=qux&baz=quux&corge');
/* =>
{ foo: 'bar', baz: ['qux', 'quux'], corge: '' }
*/
 
querystring.stringify({ foo: 'bar', baz: ['qux', 'quux'], corge: '' });
/* =>
'foo=bar&baz=qux&baz=quux&corge='
*/
Zlib
官方文档：http://nodejs.org/api/zlib.html

zlib 模块提供了数据压缩和解压的功能。当我们处理 HTTP 请求和响应时，可能需要用到这个模块。

首先我们看一个使用 zlib 模块压缩 HTTP 响应体数据的例子。这个例子中，判断了客户端是否支持 gzip，并在支持的情况下使用 zlib 模块返回 gzip 之后的响应体数据。

http.createServer(function (request, response) {
    var i = 1024,
        data = '';
 
    while (i--) {
        data += '.';
    }
 
    if ((request.headers['accept-encoding'] || '').indexOf('gzip') !== -1) {
        zlib.gzip(data, function (err, data) {
            response.writeHead(200, {
                'Content-Type': 'text/plain',
                'Content-Encoding': 'gzip'
            });
            response.end(data);
        });
    } else {
        response.writeHead(200, {
            'Content-Type': 'text/plain'
        });
        response.end(data);
    }
}).listen(80);
接着我们看一个使用 zlib 模块解压 HTTP 响应体数据的例子。这个例子中，判断了服务端响应是否使用 gzip 压缩，并在压缩的情况下使用 zlib 模块解压响应体数据。

var options = {
        hostname: 'www.example.com',
        port: 80,
        path: '/',
        method: 'GET',
        headers: {
            'Accept-Encoding': 'gzip, deflate'
        }
    };
 
http.request(options, function (response) {
    var body = [];
 
    response.on('data', function (chunk) {
        body.push(chunk);
    });
 
    response.on('end', function () {
        body = Buffer.concat(body);
 
        if (response.headers['content-encoding'] === 'gzip') {
            zlib.gunzip(body, function (err, data) {
                console.log(data.toString());
            });
        } else {
            console.log(data.toString());
        }
    });
}).end();
Net
官方文档：http://nodejs.org/api/net.html

net 模块可用于创建 Socket 服务器或 Socket 客户端。由于 Socket 在前端领域的使用范围还不是很广，这里先不涉及到 WebSocket 的介绍，仅仅简单演示一下如何从 Socket 层面来实现 HTTP 请求和响应。

首先我们来看一个使用 Socket 搭建一个很不严谨的 HTTP 服务器的例子。这个 HTTP 服务器不管收到啥请求，都固定返回相同的响应。

net.createServer(function (conn) {
    conn.on('data', function (data) {
        conn.write([
            'HTTP/1.1 200 OK',
            'Content-Type: text/plain',
            'Content-Length: 11',
            '',
            'Hello World'
        ].join('\n'));
    });
}).listen(80);
接着我们来看一个使用 Socket 发起 HTTP 客户端请求的例子。这个例子中，Socket 客户端在建立连接后发送了一个 HTTP GET 请求，并通过 data 事件监听函数来获取服务器响应。

var options = {
        port: 80,
        host: 'www.example.com'
    };
 
var client = net.connect(options, function () {
        client.write([
            'GET / HTTP/1.1',
            'User-Agent: curl/7.26.0',
            'Host: www.baidu.com',
            'Accept: */*',
            '',
            ''
        ].join('\n'));
    });
 
client.on('data', function (data) {
    console.log(data.toString());
    client.end();
});
灵机一点
使用 NodeJS 操作网络，特别是操作 HTTP 请求和响应时会遇到一些惊喜，这里对一些常见问题做解答。

问： 为什么通过 headers 对象访问到的 HTTP 请求头或响应头字段不是驼峰的？
答： 从规范上讲，HTTP 请求头和响应头字段都应该是驼峰的。但现实是残酷的，不是每个 HTTP 服务端或客户端程序都严格遵循规范，所以 NodeJS 在处理从别的客户端或服务端收到的头字段时，都统一地转换为了小写字母格式，以便开发者能使用统一的方式来访问头字段，例如 headers[‘content-length’]。

问： 为什么 http 模块创建的 HTTP 服务器返回的响应是 chunked 传输方式的？
答： 因为默认情况下，使用.writeHead 方法写入响应头后，允许使用.write 方法写入任意长度的响应体数据，并使用.end 方法结束一个响应。由于响应体数据长度不确定，因此 NodeJS 自动在响应头里添加了 Transfer-Encoding: chunked 字段，并采用 chunked 传输方式。但是当响应体数据长度确定时，可使用.writeHead 方法在响应头里加上 Content-Length 字段，这样做之后 NodeJS 就不会自动添加 Transfer-Encoding 字段和使用 chunked 传输方式。

问： 为什么使用 http 模块发起 HTTP 客户端请求时，有时候会发生 socket hang up 错误？
答： 发起客户端 HTTP 请求前需要先创建一个客户端。http 模块提供了一个全局客户端 http.globalAgent，可以让我们使用.request 或.get 方法时不用手动创建客户端。但是全局客户端默认只允许 5 个并发 Socket 连接，当某一个时刻 HTTP 客户端请求创建过多，超过这个数字时，就会发生 socket hang up 错误。解决方法也很简单，通过 http.globalAgent.maxSockets 属性把这个数字改大些即可。另外，https 模块遇到这个问题时也一样通过 https.globalAgent.maxSockets 属性来处理。

小结
本章介绍了使用 NodeJS 操作网络时需要的 API 以及一些坑回避技巧，总结起来有以下几点：

http 和 https 模块支持服务端模式和客户端模式两种使用方式。request 和 response 对象除了用于读写头数据外，都可以当作数据流来操作。url.parse 方法加上 request.url 属性是处理 HTTP 请求时的固定搭配。使用 zlib 模块可以减少使用 HTTP 协议时的数据传输量。通过 net 模块的 Socket 服务器与客户端可对 HTTP 协议做底层操作。小心踩坑。
1 开门红
2API 走马观花
2.1HTTP
2.2HTTPS
2.3URL
2.4Query String
2.5Zlib
2.6Net
3 灵机一点
4 小结
关于我们 联系我们 广告服务 免责声明
© 2012-2016 jqhtml.com · 湘 ICP 备 16001111 号-1 · 托管于 阿里云 & 又拍云
* 进程管理
NodeJS 可以感知和控制自身进程的运行环境和状态，也可以创建子进程并与其协同工作，这使得 NodeJS 可以把多个程序组合在一起共同完成某项工作，并在其中充当胶水和调度器的作用。本章除了介绍与之相关的 NodeJS 内置模块外，还会重点介绍典型的使用场景。

开门红
我们已经知道了 NodeJS 自带的 fs 模块比较基础，把一个目录里的所有文件和子目录都拷贝到另一个目录里需要写不少代码。另外我们也知道，终端下的 cp 命令比较好用，一条 cp -r source/* target 命令就能搞定目录拷贝。那我们首先看看如何使用 NodeJS 调用终端命令来简化目录拷贝，示例代码如下：

var child_process = require('child_process');
var util = require('util');
 
function copy(source, target, callback) {
    child_process.exec(
        util.format('cp -r %s/* %s', source, target), callback);
}
 
copy('a', 'b', function (err) {
    // ...
});
从以上代码中可以看到，子进程是异步运行的，通过回调函数返回执行结果。

API 走马观花
我们先大致看看 NodeJS 提供了哪些和进程管理有关的 API。这里并不逐一介绍每个 API 的使用方法，官方文档已经做得很好了。

Process
官方文档：http://nodejs.org/api/process.html

任何一个进程都有启动进程时使用的命令行参数，有标准输入标准输出，有运行权限，有运行环境和运行状态。在 NodeJS 中，可以通过 process 对象感知和控制 NodeJS 自身进程的方方面面。另外需要注意的是，process 不是内置模块，而是一个全局对象，因此在任何地方都可以直接使用。

Child Process
官方文档：http://nodejs.org/api/child_process.html

使用 child_process 模块可以创建和控制子进程。该模块提供的 API 中最核心的是.spawn，其余 API 都是针对特定使用场景对它的进一步封装，算是一种语法糖。

Cluster
官方文档：http://nodejs.org/api/cluster.html

cluster 模块是对 child_process 模块的进一步封装，专用于解决单进程 NodeJS Web 服务器无法充分利用多核 CPU 的问题。使用该模块可以简化多进程服务器程序的开发，让每个核上运行一个工作进程，并统一通过主进程监听端口和分发请求。

应用场景
和进程管理相关的 API 单独介绍起来比较枯燥，因此这里从一些典型的应用场景出发，分别介绍一些重要 API 的使用方法。

如何获取命令行参数
在 NodeJS 中可以通过 process.argv 获取命令行参数。但是比较意外的是，node 执行程序路径和主模块文件路径固定占据了 argv[0]和 argv[1]两个位置，而第一个命令行参数从 argv[2]开始。为了让 argv 使用起来更加自然，可以按照以下方式处理。

function main(argv) {
    // ...
}
 
main(process.argv.slice(2));
如何退出程序
通常一个程序做完所有事情后就正常退出了，这时程序的退出状态码为 0。或者一个程序运行时发生了异常后就挂了，这时程序的退出状态码不等于 0。如果我们在代码中捕获了某个异常，但是觉得程序不应该继续运行下去，需要立即退出，并且需要把退出状态码设置为指定数字，比如 1，就可以按照以下方式：

try {
    // ...
} catch (err) {
    // ...
    process.exit(1);
}
如何控制输入输出
NodeJS 程序的标准输入流（stdin）、一个标准输出流（stdout）、一个标准错误流（stderr）分别对应 process.stdin、process.stdout 和 process.stderr，第一个是只读数据流，后边两个是只写数据流，对它们的操作按照对数据流的操作方式即可。例如，console.log 可以按照以下方式实现。

function log() {
    process.stdout.write(
        util.format.apply(util, arguments) + '\n');
}
如何降权
在 Linux 系统下，我们知道需要使用 root 权限才能监听 1024 以下端口。但是一旦完成端口监听后，继续让程序运行在 root 权限下存在安全隐患，因此最好能把权限降下来。以下是这样一个例子。

http.createServer(callback).listen(80, function () {
    var env = process.env,
        uid = parseInt(env['SUDO_UID'] || process.getuid(), 10),
        gid = parseInt(env['SUDO_GID'] || process.getgid(), 10);
 
    process.setgid(gid);
    process.setuid(uid);
});
上例中有几点需要注意：

如果是通过 sudo 获取 root 权限的，运行程序的用户的 UID 和 GID 保存在环境变量 SUDO_UID 和 SUDO_GID 里边。如果是通过 chmod +s 方式获取 root 权限的，运行程序的用户的 UID 和 GID 可直接通过 process.getuid 和 process.getgid 方法获取。process.setuid 和 process.setgid 方法只接受 number 类型的参数。降权时必须先降 GID 再降 UID，否则顺序反过来的话就没权限更改程序的 GID 了。如何创建子进程
以下是一个创建 NodeJS 子进程的例子。

var child = child_process.spawn('node', [ 'xxx.js' ]);
 
child.stdout.on('data', function (data) {
    console.log('stdout: ' + data);
});
 
child.stderr.on('data', function (data) {
    console.log('stderr: ' + data);
});
 
child.on('close', function (code) {
    console.log('child process exited with code ' + code);
});
上例中使用了.spawn(exec, args, options)方法，该方法支持三个参数。第一个参数是执行文件路径，可以是执行文件的相对或绝对路径，也可以是根据 PATH 环境变量能找到的执行文件名。第二个参数中，数组中的每个成员都按顺序对应一个命令行参数。第三个参数可选，用于配置子进程的执行环境与行为。

另外，上例中虽然通过子进程对象的.stdout 和.stderr 访问子进程的输出，但通过 options.stdio 字段的不同配置，可以将子进程的输入输出重定向到任何数据流上，或者让子进程共享父进程的标准输入输出流，或者直接忽略子进程的输入输出。

进程间如何通讯
在 Linux 系统下，进程之间可以通过信号互相通信。以下是一个例子。

/* parent.js */
var child = child_process.spawn('node', [ 'child.js' ]);
 
child.kill('SIGTERM');
 
/* child.js */
process.on('SIGTERM', function () {
    cleanUp();
    process.exit(0);
});
在上例中，父进程通过.kill 方法向子进程发送 SIGTERM 信号，子进程监听 process 对象的 SIGTERM 事件响应信号。不要被.kill 方法的名称迷惑了，该方法本质上是用来给进程发送信号的，进程收到信号后具体要做啥，完全取决于信号的种类和进程自身的代码。

另外，如果父子进程都是 NodeJS 进程，就可以通过 IPC（进程间通讯）双向传递数据。以下是一个例子。

/* parent.js */
var child = child_process.spawn('node', [ 'child.js' ], {
        stdio: [ 0, 1, 2, 'ipc' ]
    });
 
child.on('message', function (msg) {
    console.log(msg);
});
 
child.send({ hello: 'hello' });
 
/* child.js */
process.on('message', function (msg) {
    msg.hello = msg.hello.toUpperCase();
    process.send(msg);
});
可以看到，父进程在创建子进程时，在 options.stdio 字段中通过 ipc 开启了一条 IPC 通道，之后就可以监听子进程对象的 message 事件接收来自子进程的消息，并通过.send 方法给子进程发送消息。在子进程这边，可以在 process 对象上监听 message 事件接收来自父进程的消息，并通过.send 方法向父进程发送消息。数据在传递过程中，会先在发送端使用 JSON.stringify 方法序列化，再在接收端使用 JSON.parse 方法反序列化。

如何守护子进程
守护进程一般用于监控工作进程的运行状态，在工作进程不正常退出时重启工作进程，保障工作进程不间断运行。以下是一种实现方式。

/* daemon.js */
function spawn(mainModule) {
    var worker = child_process.spawn('node', [ mainModule ]);
 
    worker.on('exit', function (code) {
        if (code !== 0) {
            spawn(mainModule);
        }
    });
}
 
spawn('worker.js');
可以看到，工作进程非正常退出时，守护进程立即重启工作进程。

小结
本章介绍了使用 NodeJS 管理进程时需要的 API 以及主要的应用场景，总结起来有以下几点：

使用 process 对象管理自身。使用 child_process 模块创建和管理子进程。
1 开门红
2API 走马观花
2.1Process
2.2Child Process
2.3Cluster
3 应用场景
3.1 如何获取命令行参数
3.2 如何退出程序
3.3 如何控制输入输出
3.4 如何降权
3.5 如何创建子进程
3.6 进程间如何通讯
3.7 如何守护子进程
4 小结
关于我们 联系我们 广告服务 免责声明
© 2012-2016 jqhtml.com · 湘 ICP 备 16001111 号-1 · 托管于 阿里云 & 又拍云
* 异步编程
NodeJS 最大的卖点——事件机制和异步 IO，对开发者并不是透明的。开发者需要按异步方式编写代码才用得上这个卖点，而这一点也遭到了一些 NodeJS 反对者的抨击。但不管怎样，异步编程确实是 NodeJS 最大的特点，没有掌握异步编程就不能说是真正学会了 NodeJS。本章将介绍与异步编程相关的各种知识。

回调
在代码中，异步编程的直接体现就是回调。异步编程依托于回调来实现，但不能说使用了回调后程序就异步化了。我们首先可以看看以下代码。

function heavyCompute(n, callback) {
    var count = 0,
        i, j;
 
    for (i = n; i > 0; --i) {
        for (j = n; j > 0; --j) {
            count += 1;
        }
    }
 
    callback(count);
}
 
heavyCompute(10000, function (count) {
    console.log(count);
});
 
console.log('hello');
 
-- Console ------------------------------
100000000
hello
可以看到，以上代码中的回调函数仍然先于后续代码执行。JS 本身是单线程运行的，不可能在一段代码还未结束运行时去运行别的代码，因此也就不存在异步执行的概念。

但是，如果某个函数做的事情是创建一个别的线程或进程，并与 JS 主线程并行地做一些事情，并在事情做完后通知 JS 主线程，那情况又不一样了。我们接着看看以下代码。

setTimeout(function () {
    console.log('world');
}, 1000);
 
console.log('hello');
 
-- Console ------------------------------
hello
world
这次可以看到，回调函数后于后续代码执行了。如同上边所说，JS 本身是单线程的，无法异步执行，因此我们可以认为 setTimeout 这类 JS 规范之外的由运行环境提供的特殊函数做的事情是创建一个平行线程后立即返回，让 JS 主进程可以接着执行后续代码，并在收到平行进程的通知后再执行回调函数。除了 setTimeout、setInterval 这些常见的，这类函数还包括 NodeJS 提供的诸如 fs.readFile 之类的异步 API。

另外，我们仍然回到 JS 是单线程运行的这个事实上，这决定了 JS 在执行完一段代码之前无法执行包括回调函数在内的别的代码。也就是说，即使平行线程完成工作了，通知 JS 主线程执行回调函数了，回调函数也要等到 JS 主线程空闲时才能开始执行。以下就是这么一个例子。

function heavyCompute(n) {
    var count = 0,
        i, j;
 
    for (i = n; i > 0; --i) {
        for (j = n; j > 0; --j) {
            count += 1;
        }
    }
}
 
var t = new Date();
 
setTimeout(function () {
    console.log(new Date() - t);
}, 1000);
 
heavyCompute(50000);
 
-- Console ------------------------------
8520
可以看到，本来应该在 1 秒后被调用的回调函数因为 JS 主线程忙于运行其它代码，实际执行时间被大幅延迟。

代码设计模式
异步编程有很多特有的代码设计模式，为了实现同样的功能，使用同步方式和异步方式编写的代码会有很大差异。以下分别介绍一些常见的模式。

函数返回值
使用一个函数的输出作为另一个函数的输入是很常见的需求，在同步方式下一般按以下方式编写代码：

var output = fn1(fn2('input'));
// Do something.
而在异步方式下，由于函数执行结果不是通过返回值，而是通过回调函数传递，因此一般按以下方式编写代码：

fn2('input', function (output2) {
    fn1(output2, function (output1) {
        // Do something.
    });
});
可以看到，这种方式就是一个回调函数套一个回调函多，套得太多了很容易写出>形状的代码。

遍历数组
在遍历数组时，使用某个函数依次对数据成员做一些处理也是常见的需求。如果函数是同步执行的，一般就会写出以下代码：

var len = arr.length,
    i = 0;
 
for (; i < len; ++i) {
    arr[i] = sync(arr[i]);
}
 
// All array items have processed.
如果函数是异步执行的，以上代码就无法保证循环结束后所有数组成员都处理完毕了。如果数组成员必须一个接一个串行处理，则一般按照以下方式编写异步代码：

(function next(i, len, callback) {
    if (i < len) {
        async(arr[i], function (value) {
            arr[i] = value;
            next(i + 1, len, callback);
        });
    } else {
        callback();
    }
}(0, arr.length, function () {
    // All array items have processed.
}));
可以看到，以上代码在异步函数执行一次并返回执行结果后才传入下一个数组成员并开始下一轮执行，直到所有数组成员处理完毕后，通过回调的方式触发后续代码的执行。

如果数组成员可以并行处理，但后续代码仍然需要所有数组成员处理完毕后才能执行的话，则异步代码会调整成以下形式：

(function (i, len, count, callback) {
    for (; i < len; ++i) {
        (function (i) {
            async(arr[i], function (value) {
                arr[i] = value;
                if (++count === len) {
                    callback();
                }
            });
        }(i));
    }
}(0, arr.length, 0, function () {
    // All array items have processed.
}));
可以看到，与异步串行遍历的版本相比，以上代码并行处理所有数组成员，并通过计数器变量来判断什么时候所有数组成员都处理完毕了。

异常处理
JS 自身提供的异常捕获和处理机制——try..catch..，只能用于同步执行的代码。以下是一个例子。

function sync(fn) {
    return fn();
}
 
try {
    sync(null);
    // Do something.
} catch (err) {
    console.log('Error: %s', err.message);
}
 
-- Console ------------------------------
Error: object is not a function
可以看到，异常会沿着代码执行路径一直冒泡，直到遇到第一个 try 语句时被捕获住。但由于异步函数会打断代码执行路径，异步函数执行过程中以及执行之后产生的异常冒泡到执行路径被打断的位置时，如果一直没有遇到 try 语句，就作为一个全局异常抛出。以下是一个例子。

function async(fn, callback) {
    // Code execution path breaks here.
    setTimeout(function ()　{
        callback(fn());
    }, 0);
}
 
try {
    async(null, function (data) {
        // Do something.
    });
} catch (err) {
    console.log('Error: %s', err.message);
}
 
-- Console ------------------------------
/home/user/test.js:4
        callback(fn());
                 ^
TypeError: object is not a function
    at null._onTimeout (/home/user/test.js:4:13)
    at Timer.listOnTimeout [as ontimeout] (timers.js:110:15)
因为代码执行路径被打断了，我们就需要在异常冒泡到断点之前用 try 语句把异常捕获住，并通过回调函数传递被捕获的异常。于是我们可以像下边这样改造上边的例子。

function async(fn, callback) {
    // Code execution path breaks here.
    setTimeout(function ()　{
        try {
            callback(null, fn());
        } catch (err) {
            callback(err);
        }
    }, 0);
}
 
async(null, function (err, data) {
    if (err) {
        console.log('Error: %s', err.message);
    } else {
        // Do something.
    }
});
 
-- Console ------------------------------
Error: object is not a function
可以看到，异常再次被捕获住了。在 NodeJS 中，几乎所有异步 API 都按照以上方式设计，回调函数中第一个参数都是 err。因此我们在编写自己的异步函数时，也可以按照这种方式来处理异常，与 NodeJS 的设计风格保持一致。

有了异常处理方式后，我们接着可以想一想一般我们是怎么写代码的。基本上，我们的代码都是做一些事情，然后调用一个函数，然后再做一些事情，然后再调用一个函数，如此循环。如果我们写的是同步代码，只需要在代码入口点写一个 try 语句就能捕获所有冒泡上来的异常，示例如下。

function main() {
    // Do something.
    syncA();
    // Do something.
    syncB();
    // Do something.
    syncC();
}
 
try {
    main();
} catch (err) {
    // Deal with exception.
}
但是，如果我们写的是异步代码，就只有呵呵了。由于每次异步函数调用都会打断代码执行路径，只能通过回调函数来传递异常，于是我们就需要在每个回调函数里判断是否有异常发生，于是只用三次异步函数调用，就会产生下边这种代码。

function main(callback) {
    // Do something.
    asyncA(function (err, data) {
        if (err) {
            callback(err);
        } else {
            // Do something
            asyncB(function (err, data) {
                if (err) {
                    callback(err);
                } else {
                    // Do something
                    asyncC(function (err, data) {
                        if (err) {
                            callback(err);
                        } else {
                            // Do something
                            callback(null);
                        }
                    });
                }
            });
        }
    });
}
 
main(function (err) {
    if (err) {
        // Deal with exception.
    }
});
可以看到，回调函数已经让代码变得复杂了，而异步方式下对异常的处理更加剧了代码的复杂度。如果 NodeJS 的最大卖点最后变成这个样子，那就没人愿意用 NodeJS 了，因此接下来会介绍 NodeJS 提供的一些解决方案。

域（Domain）
官方文档：http://nodejs.org/api/domain.html

NodeJS 提供了 domain 模块，可以简化异步代码的异常处理。在介绍该模块之前，我们需要首先理解“域”的概念。简单的讲，一个域就是一个 JS 运行环境，在一个运行环境中，如果一个异常没有被捕获，将作为一个全局异常被抛出。NodeJS 通过 process 对象提供了捕获全局异常的方法，示例代码如下

process.on('uncaughtException', function (err) {
    console.log('Error: %s', err.message);
});
 
setTimeout(function (fn) {
    fn();
});
 
-- Console ------------------------------
Error: undefined is not a function
虽然全局异常有个地方可以捕获了，但是对于大多数异常，我们希望尽早捕获，并根据结果决定代码的执行路径。我们用以下 HTTP 服务器代码作为例子：

function async(request, callback) {
    // Do something.
    asyncA(request, function (err, data) {
        if (err) {
            callback(err);
        } else {
            // Do something
            asyncB(request, function (err, data) {
                if (err) {
                    callback(err);
                } else {
                    // Do something
                    asyncC(request, function (err, data) {
                        if (err) {
                            callback(err);
                        } else {
                            // Do something
                            callback(null, data);
                        }
                    });
                }
            });
        }
    });
}
 
http.createServer(function (request, response) {
    async(request, function (err, data) {
        if (err) {
            response.writeHead(500);
            response.end();
        } else {
            response.writeHead(200);
            response.end(data);
        }
    });
});
以上代码将请求对象交给异步函数处理后，再根据处理结果返回响应。这里采用了使用回调函数传递异常的方案，因此 async 函数内部如果再多几个异步函数调用的话，代码就变成上边这副鬼样子了。为了让代码好看点，我们可以在每处理一个请求时，使用 domain 模块创建一个子域（JS 子运行环境）。在子域内运行的代码可以随意抛出异常，而这些异常可以通过子域对象的 error 事件统一捕获。于是以上代码可以做如下改造：

function async(request, callback) {
    // Do something.
    asyncA(request, function (data) {
        // Do something
        asyncB(request, function (data) {
            // Do something
            asyncC(request, function (data) {
                // Do something
                callback(data);
            });
        });
    });
}
 
http.createServer(function (request, response) {
    var d = domain.create();
 
    d.on('error', function () {
        response.writeHead(500);
        response.end();
    });
 
    d.run(function () {
        async(request, function (data) {
            response.writeHead(200);
            response.end(data);
        });
    });
});
可以看到，我们使用.create 方法创建了一个子域对象，并通过.run 方法进入需要在子域中运行的代码的入口点。而位于子域中的异步函数回调函数由于不再需要捕获异常，代码一下子瘦身很多。

陷阱
无论是通过 process 对象的 uncaughtException 事件捕获到全局异常，还是通过子域对象的 error 事件捕获到了子域异常，在 NodeJS 官方文档里都强烈建议处理完异常后立即重启程序，而不是让程序继续运行。按照官方文档的说法，发生异常后的程序处于一个不确定的运行状态，如果不立即退出的话，程序可能会发生严重内存泄漏，也可能表现得很奇怪。

但这里需要澄清一些事实。JS 本身的 throw..try..catch 异常处理机制并不会导致内存泄漏，也不会让程序的执行结果出乎意料，但 NodeJS 并不是存粹的 JS。NodeJS 里大量的 API 内部是用 C/C++实现的，因此 NodeJS 程序的运行过程中，代码执行路径穿梭于 JS 引擎内部和外部，而 JS 的异常抛出机制可能会打断正常的代码执行流程，导致 C/C++部分的代码表现异常，进而导致内存泄漏等问题。

因此，使用 uncaughtException 或 domain 捕获异常，代码执行路径里涉及到了 C/C++部分的代码时，如果不能确定是否会导致内存泄漏等问题，最好在处理完异常后重启程序比较妥当。而使用 try 语句捕获异常时一般捕获到的都是 JS 本身的异常，不用担心上诉问题。

小结
本章介绍了 JS 异步编程相关的知识，总结起来有以下几点：

不掌握异步编程就不算学会 NodeJS。异步编程依托于回调来实现，而使用回调不一定就是异步编程。异步编程下的函数间数据传递、数组遍历和异常处理与同步编程有很大差别。使用 domain 模块简化异步代码的异常处理，并小心陷阱。
1 回调
2 代码设计模式
2.1 函数返回值
2.2 遍历数组
2.3 异常处理
3 域（Domain）
3.1 陷阱
4 小结
* 大示例
学习讲究的是学以致用和融会贯通。至此我们已经分别介绍了 NodeJS 的很多知识点，本章作为最后一章，将完整地介绍一个使用 NodeJS 开发 Web 服务器的示例。

需求
我们要开发的是一个简单的静态文件合并服务器，该服务器需要支持类似以下格式的 JS 或 CSS 文件合并请求。

http://assets.example.com/foo/??bar.js,baz.js
在以上 URL 中，??是一个分隔符，之前是需要合并的多个文件的 URL 的公共部分，之后是使用,分隔的差异部分。因此服务器处理这个 URL 时，返回的是以下两个文件按顺序合并后的内容。

/foo/bar.js
/foo/baz.js
另外，服务器也需要能支持类似以下格式的普通的 JS 或 CSS 文件请求。

http://assets.example.com/foo/bar.js
以上就是整个需求。

第一次迭代
快速迭代是一种不错的开发方式，因此我们在第一次迭代时先实现服务器的基本功能。

设计
简单分析了需求之后，我们大致会得到以下的设计方案。

           +---------+   +-----------+   +----------+
request -->|  parse  |-->|  combine  |-->|  output  |--> response
           +---------+   +-----------+   +----------+
也就是说，服务器会首先分析 URL，得到请求的文件的路径和类型（MIME）。然后，服务器会读取请求的文件，并按顺序合并文件内容。最后，服务器返回响应，完成对一次请求的处理。

另外，服务器在读取文件时需要有个根目录，并且服务器监听的 HTTP 端口最好也不要写死在代码里，因此服务器需要是可配置的。

实现
根据以上设计，我们写出了第一版代码如下。

var fs = require('fs'),
    path = require('path'),
    http = require('http');
 
var MIME = {
    '.css': 'text/css',
    '.js': 'application/javascript'
};
 
function combineFiles(pathnames, callback) {
    var output = [];
 
    (function next(i, len) {
        if (i < len) {
            fs.readFile(pathnames[i], function (err, data) {
                if (err) {
                    callback(err);
                } else {
                    output.push(data);
                    next(i + 1, len);
                }
            });
        } else {
            callback(null, Buffer.concat(output));
        }
    }(0, pathnames.length));
}
 
function main(argv) {
    var config = JSON.parse(fs.readFileSync(argv[0], 'utf-8')),
        root = config.root || '.',
        port = config.port || 80;
 
    http.createServer(function (request, response) {
        var urlInfo = parseURL(root, request.url);
 
        combineFiles(urlInfo.pathnames, function (err, data) {
            if (err) {
                response.writeHead(404);
                response.end(err.message);
            } else {
                response.writeHead(200, {
                    'Content-Type': urlInfo.mime
                });
                response.end(data);
            }
        });
    }).listen(port);
}
 
function parseURL(root, url) {
    var base, pathnames, parts;
 
    if (url.indexOf('??') === -1) {
        url = url.replace('/', '/??');
    }
 
    parts = url.split('??');
    base = parts[0];
    pathnames = parts[1].split(',').map(function (value) {
        return path.join(root, base, value);
    });
 
    return {
        mime: MIME[path.extname(pathnames[0])] || 'text/plain',
        pathnames: pathnames
    };
}
 
main(process.argv.slice(2));
以上代码完整实现了服务器所需的功能，并且有以下几点值得注意：

使用命令行参数传递 JSON 配置文件路径，入口函数负责读取配置并创建服务器。入口函数完整描述了程序的运行逻辑，其中解析 URL 和合并文件的具体实现封装在其它两个函数里。解析 URL 时先将普通 URL 转换为了文件合并 URL，使得两种 URL 的处理方式可以一致。合并文件时使用异步 API 读取文件，避免服务器因等待磁盘 IO 而发生阻塞。
我们可以把以上代码保存为 server.js，之后就可以通过 node server.js config.json 命令启动程序，于是我们的第一版静态文件合并服务器就顺利完工了。

另外，以上代码存在一个不那么明显的逻辑缺陷。例如，使用以下 URL 请求服务器时会有惊喜。

http://assets.example.com/foo/bar.js,foo/baz.js
经过分析之后我们会发现问题出在/被自动替换/??这个行为上，而这个问题我们可以到第二次迭代时再解决。

第二次迭代
在第一次迭代之后，我们已经有了一个可工作的版本，满足了功能需求。接下来我们需要从性能的角度出发，看看代码还有哪些改进余地。

设计
把 map 方法换成 for 循环或许会更快一些，但第一版代码最大的性能问题存在于从读取文件到输出响应的过程当中。我们以处理/??a.js,b.js,c.js 这个请求为例，看看整个处理过程中耗时在哪儿。

发送请求       等待服务端响应         接收响应
---------+----------------------+------------->
         --                                        解析请求
           ------                                  读取 a.js
                 ------                            读取 b.js
                       ------                      读取 c.js
                             --                    合并数据
                               --                  输出响应
可以看到，第一版代码依次把请求的文件读取到内存中之后，再合并数据和输出响应。这会导致以下两个问题：

当请求的文件比较多比较大时，串行读取文件会比较耗时，从而拉长了服务端响应等待时间。由于每次响应输出的数据都需要先完整地缓存在内存里，当服务器请求并发数较大时，会有较大的内存开销。
对于第一个问题，很容易想到把读取文件的方式从串行改为并行。但是别这样做，因为对于机械磁盘而言，因为只有一个磁头，尝试并行读取文件只会造成磁头频繁抖动，反而降低 IO 效率。而对于固态硬盘，虽然的确存在多个并行 IO 通道，但是对于服务器并行处理的多个请求而言，硬盘已经在做并行 IO 了，对单个请求采用并行 IO 无异于拆东墙补西墙。因此，正确的做法不是改用并行 IO，而是一边读取文件一边输出响应，把响应输出时机提前至读取第一个文件的时刻。这样调整后，整个请求处理过程变成下边这样。

发送请求 等待服务端响应 接收响应
---------+----+------------------------------->
         --                                        解析请求
           --                                      检查文件是否存在
             --                                    输出响应头
               ------                              读取和输出 a.js
                     ------                        读取和输出 b.js
                           ------                  读取和输出 c.js
按上述方式解决第一个问题后，因为服务器不需要完整地缓存每个请求的输出数据了，第二个问题也迎刃而解。

实现
根据以上设计，第二版代码按以下方式调整了部分函数。

function main(argv) {
    var config = JSON.parse(fs.readFileSync(argv[0], 'utf-8')),
        root = config.root || '.',
        port = config.port || 80;
 
    http.createServer(function (request, response) {
        var urlInfo = parseURL(root, request.url);
 
        validateFiles(urlInfo.pathnames, function (err, pathnames) {
            if (err) {
                response.writeHead(404);
                response.end(err.message);
            } else {
                response.writeHead(200, {
                    'Content-Type': urlInfo.mime
                });
                outputFiles(pathnames, response);
            }
        });
    }).listen(port);
}
 
function outputFiles(pathnames, writer) {
    (function next(i, len) {
        if (i < len) {
            var reader = fs.createReadStream(pathnames[i]);
 
            reader.pipe(writer, { end: false });
            reader.on('end', function() {
                next(i + 1, len);
            });
        } else {
            writer.end();
        }
    }(0, pathnames.length));
}
 
function validateFiles(pathnames, callback) {
    (function next(i, len) {
        if (i < len) {
            fs.stat(pathnames[i], function (err, stats) {
                if (err) {
                    callback(err);
                } else if (!stats.isFile()) {
                    callback(new Error());
                } else {
                    next(i + 1, len);
                }
            });
        } else {
            callback(null, pathnames);
        }
    }(0, pathnames.length));
}
可以看到，第二版代码在检查了请求的所有文件是否有效之后，立即就输出了响应头，并接着一边按顺序读取文件一边输出响应内容。并且，在读取文件时，第二版代码直接使用了只读数据流来简化代码。

第三次迭代
第二次迭代之后，服务器本身的功能和性能已经得到了初步满足。接下来我们需要从稳定性的角度重新审视一下代码，看看还需要做些什么。

设计
从工程角度上讲，没有绝对可靠的系统。即使第二次迭代的代码经过反复检查后能确保没有 bug，也很难说是否会因为 NodeJS 本身，或者是操作系统本身，甚至是硬件本身导致我们的服务器程序在某一天挂掉。因此一般生产环境下的服务器程序都配有一个守护进程，在服务挂掉的时候立即重启服务。一般守护进程的代码会远比服务进程的代码简单，从概率上可以保证守护进程更难挂掉。如果再做得严谨一些，甚至守护进程自身可以在自己挂掉时重启自己，从而实现双保险。

因此在本次迭代时，我们先利用 NodeJS 的进程管理机制，将守护进程作为父进程，将服务器程序作为子进程，并让父进程监控子进程的运行状态，在其异常退出时重启子进程。

实现
根据以上设计，我们编写了守护进程需要的代码。

var cp = require('child_process');
 
var worker;
 
function spawn(server, config) {
    worker = cp.spawn('node', [ server, config ]);
    worker.on('exit', function (code) {
        if (code !== 0) {
            spawn(server, config);
        }
    });
}
 
function main(argv) {
    spawn('server.js', argv[0]);
    process.on('SIGTERM', function () {
        worker.kill();
        process.exit(0);
    });
}
 
main(process.argv.slice(2));
此外，服务器代码本身的入口函数也要做以下调整。

function main(argv) {
    var config = JSON.parse(fs.readFileSync(argv[0], 'utf-8')),
        root = config.root || '.',
        port = config.port || 80,
        server;
 
    server = http.createServer(function (request, response) {
        ...
    }).listen(port);
 
    process.on('SIGTERM', function () {
        server.close(function () {
            process.exit(0);
        });
    });
}
我们可以把守护进程的代码保存为 daemon.js，之后我们可以通过 node daemon.js config.json 启动服务，而守护进程会进一步启动和监控服务器进程。此外，为了能够正常终止服务，我们让守护进程在接收到 SIGTERM 信号时终止服务器进程。而在服务器进程这一端，同样在收到 SIGTERM 信号时先停掉 HTTP 服务再正常退出。至此，我们的服务器程序就靠谱很多了。

第四次迭代
在我们解决了服务器本身的功能、性能和可靠性的问题后，接着我们需要考虑一下代码部署的问题，以及服务器控制的问题。

设计
一般而言，程序在服务器上有一个固定的部署目录，每次程序有更新后，都重新发布到部署目录里。而一旦完成部署后，一般也可以通过固定的服务控制脚本启动和停止服务。因此我们的服务器程序部署目录可以做如下设计。

- deploy/
    - bin/
        startws.sh
        killws.sh
    + conf/
        config.json
    + lib/
        daemon.js
        server.js
在以上目录结构中，我们分类存放了服务控制脚本、配置文件和服务器代码。

实现
按以上目录结构分别存放对应的文件之后，接下来我们看看控制脚本怎么写。首先是 start.sh。

#!/bin/sh
if [ ! -f "pid" ]
then
    node ../lib/daemon.js ../conf/config.json &
    echo $! > pid
fi
然后是 killws.sh。

#!/bin/sh
if [ -f "pid" ]
then
    kill $(tr -d '\r\n' < pid)
    rm pid
fi
于是这样我们就有了一个简单的代码部署目录和服务控制脚本，我们的服务器程序就可以上线工作了。

后续迭代
我们的服务器程序正式上线工作后，我们接下来或许会发现还有很多可以改进的点。比如服务器程序在合并 JS 文件时可以自动在 JS 文件之间插入一个;来避免一些语法问题，比如服务器程序需要提供日志来统计访问量，比如服务器程序需要能充分利用多核 CPU，等等。而此时的你，在学习了这么久 NodeJS 之后，应该已经知道该怎么做了。

小结
本章将之前零散介绍的知识点串了起来，完整地演示了一个使用 NodeJS 开发程序的例子，至此我们的课程就全部结束了。以下是对新诞生的 NodeJSer 的一些建议。

要熟悉官方 API 文档。并不是说要熟悉到能记住每个 API 的名称和用法，而是要熟悉 NodeJS 提供了哪些功能，一旦需要时知道查询 API 文档的哪块地方。要先设计再实现。在开发一个程序前首先要有一个全局的设计，不一定要很周全，但要足够能写出一些代码。要实现后再设计。在写了一些代码，有了一些具体的东西后，一定会发现一些之前忽略掉的细节。这时再反过来改进之前的设计，为第二轮迭代做准备。要充分利用三方包。NodeJS 有一个庞大的生态圈，在写代码之前先看看有没有现成的三方包能节省不少时间。
不要迷信三方包。任何事情做过头了就不好了，三方包也是一样。三方包是一个黑盒，每多使用一个三方包，就为程序增加了一份潜在风险。并且三方包很难恰好只提供程序需要的功能，每多使用一个三方包，就让程序更加臃肿一些。因此在决定使用某个三方包之前，最好三思而后行。

1 需求
2 第一次迭代
2.1 设计
2.2 实现
3 第二次迭代
3.1 设计
3.2 实现
4 第三次迭代
4.1 设计
4.2 实现
5 第四次迭代
5.1 设计
5.2 实现
6 后续迭代
7 小结
关于我们 联系我们 广告服务 免责声明
© 2012-2016 jqhtml.com · 湘 ICP 备 16001111 号-1 · 托管于 阿里云 & 又拍云
* apache 服务器例子
  #+begin_src js

    const http = require('http');

    const hostname = '127.0.0.1';
    const port = 3000;

    const server = http.createServer((req, res) => {
        res.statusCode = 200;
        res.setHeader('Content-Type', 'text/plain');
        res.end('Hello World\n');
    });

    server.listen(port, hostname, () => {
        console.log(`Server running at http://${hostname}:${port}/`);
    });
    // 浏览器 输入 http://localhost:3000
  #+end_src

  #+begin_src js

    const http = require('http');
    const fs = require('fs');
    const path = require('path');

    const hostname = '127.0.0.1';
    const port = 3000;
    const imageDir = __dirname + '/images';


    const server = http.createServer((req, res) => {
        const url = req.url;
        const _path = path.join(imageDir , url);
        fs.exists(_path,function(exists) {
            if (exists) {
                res.statusCode = 200;
                res.setHeader('Content-Type', `image/${path.extname(url).replace('.','')}`);
                fs.createReadStream(_path).pipe(res);
            } else {
                res.statusCode = 404;
                res.end('Not Found');
            }
        });

    });

    server.listen(port, hostname, () => {
        console.log(`Server running at http://${hostname}:${port}/`);
    });
    //更像服务器 了
    // 浏览器 输入 http://localhost:3000/a.png

  #+end_src
* 数据库

我们在使用 node 处理业务逻辑的时候难免要和数据打交道，这时候数据库就派上用场了。
在 node 中我们最常用的数据库有两种，redis 和 mongodb。本章也正是围绕这两个数据库
展开讲解。

### 5.1 redis

[redis](https://redis.io) 提供 key-value 类型的存储结构，是一种内存数据库，因此
数据查询速度特别快，而且它还可以通过配置来实现将数据定期备份到磁盘上的功能，一定
程度上解决进程掉线后数据恢复的问题。

node 中推荐使用 [ioredis](https://github.com/luin/ioredis) 这个驱动来对 redis 进
行操作。[redis](https://github.com/NodeRedis/node_redis) 这个驱动虽然使用人数更
多，但是从 redis 3.x 开始增加了 cluster 模式，但是这个驱动并不支持这种模式，所以
不推荐使用。

```javascript
var Redis = require('ioredis');
/**
 * 如果不传参数默认连接 127.0.0.1:6379 端口
 * */
var redis = new Redis(/*{"port" : 6379,"host" : "127.0.0.1",password: 'auth'}*/);//没有密码不需要传 password 参数
/*
var clusterRedis = [
    {
        "host":"127.0.0.1",            
        "port":6379
    },
    {
        "host":"127.0.0.1",            
        "port":6380
    }
];
var redis =  new Redis.Cluster(clusterRedis,{redisOptions:{password: 'auth'});//集群连接方式
*/

redis.set('foo', 'bar', function(err,reply) {
  console.log(err, reply);//正常情况打印 null 'OK'
});
redis.get('foo', function (err, result) {
  console.log(err,result);//正常情况打印 null 'bar'
});
```

**代码 5.1.1 redis 命令基本演示**

redis 中大多数的命令格式都是这样的 `command key param1 prama2 ...` 对应 ioredis 中的函数就是 `redis.command(key, param1, param2, ...)` 比如说 **代码 5.1.1** 中的栗子，我们在 redis-cli 中执行 `set foo bar` 命令就对应我们的 `redis.set('foo', 'bar')` 这行代码。注意到我们这里在接收处理结果的时候都是使用 callback 的方式，ioredis 内部也支持 promise 方式来接收处理结构，你只需要将回调函数去掉，改成 then 函数：

```javascript
redis.set('foo','bar').then(function(reply) {
  
});
```

**代码 5.1.2 使用 promise 方式接收返回数据**

有时候我们在使用 redis 的时候，在一个处理逻辑中要连续发送多条 redis 命令，这时候你可以考虑用 ioredis 中提供的 pipeline 或者 multi 函数。

使用 pipeline 时 ioredis 内部将一系列指令缓存到内存，最后通过 exec 函数执行后打包发送到 redis 服务器，而且它支持链式的调用方式：

```javascript
redis.pipeline().set('foo', 'bar').get('foo').exec(function (err, results) {
});
```

**代码 5.1.3 pipeline 链式调用**

甚至可以在调用每个命令的时候都加一个回调函数，这里在 get 位置加一个回调函数：

```javascript
redis.pipeline().set('foo', 'bar').get('foo',function(err,result) {
    console.log('get foo',err,result);
}).exec(function (err, results) {
    console.log('with single callback',err, results);
});
```

**代码 5.1.4 pipeline 链式函数中加回调**

当然这里还有一种更加简洁的调用方式，就是都把参数放到数组里：

```javascript
redis.pipeline([
    ['set','foo','bar'],
    ['get','foo']
]).exec(function(err,results) {
    console.log('array params',err,results);
});
```

**代码 5.1.5 pipeline 数组参数调用方式**

multi 函数跟 pipeline 函数的区别是，multi 提供了事务的功能，提交到 redis 服务器的命令的会被依次执行，pipeline 则是批量执行一批提交一批指令，但是在 redis 内部都是独立执行的，没有先后顺序，只是最终服务器将所有处理结果一起返回给了调用者。不过要想完全保证事务的原子性，我们还需要使用 watch 函数，防止我们在事务中操作一个事务的过程中，当前操作的某一个键值又被其他连接的客户端给修改了：

```javascript
redis.watch('foo');
redis.multi().set('foo', 'bar').get('foo').exec(function (err, results) {
    redis.unwatch();
    console.log('chain',err, results);
});
```

**代码 5.1.6 multi 事务操作代码**

最后一件需要重点指明的事情是，如果你当前使用了 cluster 方式连接 redis，那么最好不要使用 pipeline 和 multi 因为，ioredis 在调用这两个函数的时候，仅仅会往一个节点发送指令，但是你又不能保证你这里面操作的所有键值都在一个节点上，所以说调用这两个函数的时候很有可能会失败。

### 5.2 mongodb

 [mongodb](https://www.mongodb.com/)官方提供了 Node.js 的 mongodb 驱动，不过鉴于其提供驱动的功能太过于简单，所以又涌现了许多基于官方驱动上开发的第三方驱动。下面要讲一个使用广泛的第三方驱动， [mongoose](http://mongoosejs.com/) 。

#### 5.2.2 mongoose

前面讲了 mongskin，算是 mongodb 知识点的开胃菜，mongoskin 中的函数绝大部分和 mongodb 命令行是类似的。下面要讲的 mongoose 却稍有不同，因为其有一个 ODM (**O**bject **D**ata **M**odel) 的概念，类似于 [hibernate](http://hibernate.org/) 开发中用到的 [ORM (**O**bject **R**elational **M**apping)](https://zh.wikipedia.org/wiki/%E5%AF%B9%E8%B1%A1%E5%85%B3%E7%B3%BB%E6%98%A0%E5%B0%84) 的概念，它提供了一种将 mongodb 中字段映射为 JavaScript 对象属性的能力。如果我们用 mongoose 来实现一系列的增删改查操作，就必须先定义一个 Schema，不过下面要先讲怎样在 mongoose 中建立连接，否则接下来的例子就没法运行了：

```javascript
var mongoose = require('mongoose');

mongoose.connect('mongodb://localhost/live', {/*user:'username',pass:'password'*/}); // connect to database
```

**代码 5.2.2.1 mongoose 建立连接代码**

在 mongoose 中使用 [connect](http://mongoosejs.com/docs/connections.html) 函数可以初始化 mongodb 连接，第一个参数代表 mongodb 的连接字符串，第二个参数存放连接控制参数，比如说用户名、密码之类的。其实第一个字符串中有更多连接参数控制，可以参考 mongodb 的 [官方文档](https://docs.mongodb.com/manual/reference/connection-string/)，其中就包括用户名和密码信息（格式为` mongodb://username:password@host:port/database?options...`），但是如果你的密码中有特殊字符的话（比如说`@`），就比较难办了，所以将用户名和密码放到第二个参数中比较保险。

接下来就将 mongoose 中非常之重要的 Schema，首先直接构造一个我们在 5.2.1 小节中使用过的 article 的 schema 声明：

```javascript
var mongoose = require('mongoose');
require('./conn');//代码 5.2.2.1 对应的代码

var Schema = mongoose.Schema;

var articleSchema = new Schema({
  name:  String,
  content:   String,
  comments: [{ body: String, date: Date }],
  create_at: { type: Date, default: Date.now }
});
var Article = mongoose.model('article', articleSchema);
```

**代码 5.2.2.2 声明 Schema**

通过以上代码可以总结出 shema 干的事情就是把数据库的各个字段的数据类型定义出来，最后我们还通过 model 函数获得了一个 mongoose 中的 Model 类，mongoose 的增删改查都通过这个类来进行。注意第一个参数代表表名。

```javascript
new Article({
    name:'chapter5',
    content:'Express.js 基础',
    comments : [
        {body:'写的不多',date:new Date('2016-10-11')},
        {body:'我顶',date:new Date('2017-01-01')}
    ],
    create_at:new Date('2016/07/03')
}).save(function(err,item) {
    console.log(err,item);
});
```

**代码 5.2.2.3 mongoose 插入操作**

为啥说 model 函数得到的是类呢，通过 **代码 5.2.2.3** 就可以看出，我们通过 new 生成一个对象实例，然后调用其 save 函数将其插入数据库。如果我们将 `create_at` 属性去掉，那么其值就会自动取当前时间。不过等你执行完上述代码后，查看数据库，咦，surprise，数据库里竟然多了一个名字叫 articles 的表，不是说 model 的第一个参数是执行关联的表明吗，明明在 代码 5.2.2.2 中指定的表明是 article 啊？是的，不要惊讶，mongoose 默认就是这么设计的，如果你想绑定到一个自定义的一个表明上，可以在实例化 Schema 的时候，传入一个可选参数：

```javascript
var articleSchema = new Schema({/*此处省略字段定义*/},{collection:'article'});
```

这样将 articleShema 插入 model 后得到的 Article 就绑定表 article 上了。

说了插入单条，再说一下批量插入，这时候使用 [insertMany](http://mongoosejs.com/docs/api.html#model_Model.insertMany) 函数即可：

```javascript
Article.insertMany([
    {name:'chapter1',content:'Node.js 简介 1',create_at:new Date('2016/07/01')},
    {name:'chapter1',content:'Node.js 简介 2',create_at:new Date('2016/07/01')},
    {name:'chapter1',content:'Node.js 简介 3',create_at:new Date('2016/07/01')},
    {name:'chapter2',content:'Node.js 基础 4',create_at:new Date('2016/07/02')},
    {name:'chapter2',content:'Node.js 基础 5',create_at:new Date('2016/07/02')}
],function(err,ret) {
    console.log('插入数组',err,ret);
});
```

**代码 5.2.2.4 mongoose 批量插入操作**

mongoose 的修改操作和官方 API 差不多：

```javascript
Article.update({name:'chapter2'},{
    $set:{content:'Node.js 入门'}
},function(err,ret) {
    console.log('更新单条数据',err,ret);
});
Article.update({name:'chapter2'},{
    $set:{content:'Node.js 入门'}
},{multi:true},function(err,ret) {
    console.log('更新多条数据',err,ret);
});
```

 **代码 5.2.2.5 mongoose 修改操作** 

不过它的删除稍微有些不同，就是删除的时候仅仅只能指定一个查询参数，如果你想仅仅删除一条的话，那就需要先查询出来，然后再删除。

```javascript
Article.findOne({name:'chapter1'}).remove().exec(function(err,ret) {
    console.log('删除数据',err,ret);
});
Article.remove({name:'chapter1'},function(err,ret) {
    console.log('删除数据',err,ret);
});
```

**代码 5.2.2.6 mongoose 删除操作**

上面总结了一下 mongoose 的一些基本用法，不过前面的描述还不足以体现 mongoose 的强大，下面讲到的一些高级用法，绝对能让你感到惊艳。

首先 mongoose 提供了中间件（middleware）的功能，我们可以在执行数据命令前和执行后添加钩子函数，先上代码：

```javascript
var mongoose = require('mongoose');
require('./conn');//代码 6.2.2.1 对应的代码

var Schema = mongoose.Schema;

var articleSchema = new Schema({
  name:  String,
  content:   String,
  comments: [{ body: String, date: Date }],
  create_at: { type: Date, default: Date.now }
});

articleSchema.pre('save',function(next) {
    this.content = this.name  + '\n' + this.content;
    next();
});

articleSchema.post('save', function(doc) {
    console.log('%s has been saved', doc._id);
});

var Article = mongoose.model('article', articleSchema);

new Article({
    name:'chapter5',
    content:'Node 中使用数据库',
    comments : [
        {body:'写的不多',date:new Date('2016-10-11')},
        {body:'我顶',date:new Date('2017-01-01')}
    ],
    create_at:'2017-02-11'
}).save(function(err,item) {
    console.log(err,item);
});
```

**代码 5.2.2.7 save 的中间件函数演示**

我们创建了一个 article 的 schema 定义，同时定义了两个中间件。通过 `pre('save')` 操作，我们在文章的第一行拼接了文章的标题，然后注意一定要调用 `next` 函数，否则当前数据库操作就不会得到执行。通过 `post('save')` 操作用来在数据库操作完成之后执行一些级联操作，这里我们简单的打印了一下日志。这两个中间件函数会先于 `save` 函数的回调函数前执行。

在调用 save 函数时，mongoose 中还提供了一个 validate 中间件，他会在 pre('save') 之前被触发，用来校验传入 save 函数的各个属性是不是合法：

```javascript
articleSchema.pre('validate',function(next) {
    if (/<script>/.test(this.content)) {
        return next(new Error('文章内容非法'));
    }
    next();
});
new Article({
    name:'chapter5',
    content:'Node 中使用数据库<script>alert(document.cookie)</script>',
}).save(function(err,item) {
    console.log(err,item);
});
```

**代码 5.2.2.8 save 的 validate 中间件函数演示**

上面的代码执行后，会抛出异常，因为我们的 article content 字段中包含 script 标签。令人欣喜的是，mongoose 还提供将 validate 中间件直接加到 schema 定义上的功能：

```javascript
var mongoose = require('mongoose');
require('./conn');//代码 6.2.2.1 对应的代码

var Schema = mongoose.Schema;

var articleSchema = new Schema({
    name:  {
        type:String,
        required: [true,'必须提供文章标题'],
        maxlength : [50,'文章标题不能多于 50 个字符']
    },
    isbn : {
        type:String,
        unique:true,
        sparse: true
    },
    content:  {
        type:String,
        validate:{
            validator : function() {
                return !(/<script>/.test(this.content));
            },
            message : '文章内容非法'
        }
    },
    starts : {
        type:Number,
        min:0,
        max:[5,'最多只能给 5 颗星'],
        default:0
    },
    level : {
        type:String,
        enum:['专家推荐','潜力无限','家有作家初长成','我只是个小学生']
    },
    category : {
        type:String,
        enum:{
            values:['诗歌','散文','杂文','议论文','小说'],
            message:'当前标签不支持'
        }
    },
    cover_url : {
        type:String,
        match:[/^http(s?):\/\//,'封面图格式非法']
    },
    comments: [{ body: String, date: Date }],
    create_at: { type: Date, default: Date.now }
});

articleSchema.pre('save',function(next) {
    this.content = this.name  + '\n' + this.content;
    next();
});

articleSchema.post('save', function(doc) {
    console.log('%s has been saved', doc._id);
});

var Article = mongoose.model('article', articleSchema);

new Article({
    name:'chapter5',
    content:'Node 中使用数据库<script>alert(document.cookie)</script>',
}).save(function(err,item) {
    if (err && err.name === 'ValidationError') {
        for (var field in err.errors) {
            var error = err.errors[field];
            console.error(error.message,error.path,error.value);
        }
    }
});
```

**代码 5.2.2.9 在 schema 中使用校验器**

mongoose 内建了好多校验器（validator），多余所有类型字段来说都可以使用 [required](http://mongoosejs.com/docs/api.html#schematype_SchemaType-required) 校验器，对于 Number 类型字段来说，可以使用 [min](http://mongoosejs.com/docs/api.html#schema_number_SchemaNumber-min) 和 [max](http://mongoosejs.com/docs/api.html#schema_number_SchemaNumber-max) 校验器，对于 String 类型字段来说，可以使用 [enum](http://mongoosejs.com/docs/api.html#schema_string_SchemaString-enum) [match](http://mongoosejs.com/docs/api.html#schema_string_SchemaString-match) [maxlength](http://mongoosejs.com/docs/api.html#schema_string_SchemaString-maxlength) [minlength](http://mongoosejs.com/docs/api.html#schema_string_SchemaString-minlength) 校验器。

所有校验器都可以设置在校验失败后的错误提示信息，如果相对某一个字段设置 required 约束，那么可以写成 `required:true` ，还可以进一步指定校验失败后的提示信息，也就是写成这样 `requried:[true,'这个字段必须指定']` 。但是对于 enum 来说，由于本身定义的时候就是一个数组结构（参见上面代码中 `level` 字段的定义），所以 mongoose 内部在定义其 message 属性时使用这样一个 Object 结构：`{values:[/*枚举字段定义*/],message:'出错提示信息'}` 。

还记得在**代码 5.2.2.8**中我们自定义的那个 content 字段的校验中间件不？这个中间件可以直接写到 schema 定义中，在**代码 5.2.2.9**中的 content 字段中的 validate 属性，就能替换掉之前我们写过的校验中间件。

最终你在调用 save 函数之前，这层层的字段定义约束都会被执行，如果校验出错，那么 save 回调函数返回的第一个参数中的 name 属性的值将是 `ValidationError`，让你后其 errors 属性中保存着字段的详细信息的一个 key-value 数据结构，键名是出错的字段名，值是一个包含错误详情的对象，这个对象中 message 属性就是我们在 schema 中设置的出错信息，path 是出错的字段名，value 是引起出错的具体的设置的值。

最终需要注意，unique 这个约束并不是一个  ValidationError（实际上其 name 属性值为 MongoError），所以你  save 失败后得到的 error 对象中没有 errors 属性。unique 和 sparse 仅仅是 schema 调用 mongodb 的驱动创建了数据库索引而已。**代码 5.2.2.9** 中关于 isbn 的约束，也可以通过 schema 中的 [index](http://mongoosejs.com/docs/api.html#schema_Schema-index) 函数来实现：

```javascript
articleSchema.index('isbn',{unique:true,sparse:true});
```

**代码 5.2.2.10**

前面讲了许多 mongoose 的插入、修改之类的操作，一直没有提到查询操作，下面就来讲一下查询。

在讲查询之前，需要先将我们在代码 5.2.2.9 中定义的 articleSchema 进行一下扩充，增加下面这个字段：

```javascript
_author : {type:Schema.Types.ObjectId,ref:'user'},
```

**代码 5.2.2.11**

至于其中的 _ref 属性是怎么回事，我们先买个关子，一会儿再说。

mongoose 在查询方面，有好多细节做了优化，比如说在筛选返回字段的时候可以直接通过字符串来指定：

```javascript
Article.findOne({name:nameRand},'name -_id',function(err,item) {
  if (err) {
    return console.error('findOne',err);
  }
  console.log('findOne',item && item.name === nameRand);
});
```

**代码 5.2.2.12 mongoose 查询使用字符串筛选字段**

mongoose 的查询中的各个控制参数都可以链式的调用各个函数来解决，比如说上例中用到的字段筛选可以使用 [select](http://mongoosejs.com/docs/api.html#query_Query-select) 函数来替代，即改成 `Article.findOne({name:nameRand}).select('name -_id').exec(function(err,item) {});` 当中可以添加无数个链式函数来控制查询行为，比如说 [limit](http://mongoosejs.com/docs/api.html#query_Query-limit) [skip](http://mongoosejs.com/docs/api.html#query_Query-skip) [lean](http://mongoosejs.com/docs/api.html#query_Query-lean) 等等，最后以 [exec](http://mongoosejs.com/docs/api.html#query_Query-exec) 函数结尾添加回调函数。mongoose 查询默认返回的是 [MongooseDocuments](http://mongoosejs.com/docs/api.html#document-js) 类型对象，使用 lean 函数后可以将其转成普通 javascript 对象：

```javascript
Article.find({name:/^name/}).select('_author').lean().exec(function(err,items) {
  if (err) {
    return console.error('find',err);
  }
  console.log('find',items);
});
```

**代码 5.2.2.13 mongoose 查询返回纯 javascript 对象**

转纯 javascript 对象的使用场景一般比较少见，当我们拿查询的结果作为参数来调用一些第三方库（比如说 [protobufjs](https://github.com/dcodeIO/protobuf.js) ）时，不调用 lean 的情况下会出错。

最后还要暴一下 mongoose 中的大杀器，就是联合查询，其实 mongdb 本身是没有联合查询功能的，这个功能是在 mongoose 层面延伸的功能：

```javascript
Article
  .findById(articleId)
  .select('name _author')
  .populate('_author','nickname -_id')
  .exec(function(err,item) {
  if (err) {
    return console.error('findById',err);
  }
  console.log('populate',item);
});
```

**代码 5.2.2.14 mongoose 联合查询功能**

还记得我们在**代码 5.2.2.10**中卖的关子不，我们看到其中有一个 _ref 属性，它的作用就是告诉 mongoose _author 字段的值对应 users 表中的主键字段，如果在查询的时候使用 populate 函数，则 mongoose 将在底层做两次查询（查询 articles 表 和 users 表），然后把查询结果合并。最终得到的结构演示如下：

```javascript
{ name: 'name0.6169953700982793',
  _author: { nickname: 'nick0.09724390163323227' },
  _id: 5916e9178be9f133b4798002 }
```

### 5.3 代码

本章代码参见这里：https://github.com/yunnysunny/nodebook-sample/tree/master/chapter5
